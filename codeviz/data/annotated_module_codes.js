let annotated_module_codes_data = {
    "2388": "Object.defineProperty(exports, \"__esModule\", {\r\n  value: !0,\r\n});\r\nexports.launchSolutions = exports.normalizeCompletionText = undefined;\r\nconst M_uuid_utils = require(\"uuid-utils\");\r\nconst M_async_iterable_utils_maybe = require(\"async-iterable-utils\");\r\nconst M_config_stuff = require(\"config-stuff\");\r\nconst M_completion_context = require(\"completion-context\");\r\nconst M_logging_utils = require(\"logging-utils\");\r\nconst M_openai_conn_utils = require(\"openai_conn_utils\");\r\nconst M_openai_choices_utils = require(\"openai-choices-utils\");\r\nconst M_status_reporter_maybe = require(\"status-reporter\");\r\nconst M_context_extractor_from_identation_maybe = require(\"context-extractor-from-identation-maybe\");\r\nconst M_prompt_extractor = require(\"prompt-extractor\");\r\nconst M_get_prompt_parsing_utils_maybe = require(\"get-prompt-parsing-utils\");\r\nconst M_background_context_provider = require(\"background-context-provider\");\r\nconst M_postprocess_choice = require(\"postprocess-choice\");\r\nconst M_telemetry_stuff = require(\"telemetry-stuff\");\r\nconst M_location_factory = require(\"location-factory\");\r\nconst logger = new M_logging_utils.Logger(\r\n  M_logging_utils.LogLevel.INFO,\r\n  \"solutions\"\r\n);\r\nfunction isBlockBodyFinished(e, t, n, r) {\r\n  return async (o) => {\r\n    if (r instanceof Array) {\r\n      const [i, s] = r;\r\n      return M_context_extractor_from_identation_maybe.isBlockBodyFinishedWithPrefix(\r\n        e,\r\n        t,\r\n        n,\r\n        o,\r\n        s\r\n      );\r\n    }\r\n    return M_context_extractor_from_identation_maybe.isBlockBodyFinished(\r\n      e,\r\n      t,\r\n      n,\r\n      o\r\n    );\r\n  };\r\n}\r\nasync function solnList(statusReporter, cancellationToken, solnIter) {\r\n  if (cancellationToken.isCancellationRequested) {\r\n    statusReporter.removeProgress();\r\n    return {\r\n      status: \"FinishedWithError\",\r\n      error: \"Cancelled\",\r\n    };\r\n  }\r\n  const r = await solnIter.next();\r\n  return !0 === r.done\r\n    ? (statusReporter.removeProgress(),\r\n      {\r\n        status: \"FinishedNormally\",\r\n      })\r\n    : {\r\n        status: \"Solution\",\r\n        solution: r.value,\r\n        next: solnList(statusReporter, cancellationToken, solnIter),\r\n      };\r\n}\r\nexports.normalizeCompletionText = function (e) {\r\n  return e.replace(/\\s+/g, \"\");\r\n};\r\nexports.launchSolutions = async function (ctx, t) {\r\n  var next;\r\n  var prev;\r\n  var w;\r\n\r\n  const ctxInsertPos = t.completionContext.insertPosition;\r\n  const ctxPrependToCompletion = t.completionContext.prependToCompletion;\r\n  const ctxIndentation = t.completionContext.indentation;\r\n  const locFactory = ctx.get(M_location_factory.LocationFactory);\r\n  const doc = await t.getDocument();\r\n  const k = await M_prompt_extractor.extractPrompt(ctx, doc, ctxInsertPos);\r\n\r\n  if (\"contextTooShort\" === k.type) {\r\n    t.reportCancelled();\r\n    return {\r\n      status: \"FinishedWithError\",\r\n      error: \"Context too short\",\r\n    };\r\n  }\r\n\r\n  const prompt = k.prompt;\r\n  const trailingWs = k.trailingWs;\r\n  if (trailingWs.length > 0) {\r\n    t.startPosition = locFactory.position(\r\n      t.startPosition.line,\r\n      t.startPosition.character - trailingWs.length\r\n    );\r\n  }\r\n\r\n  const cancellationToken = t.getCancellationToken();\r\n  const requestId = M_uuid_utils.v4();\r\n  t.savedTelemetryData = M_telemetry_stuff.TelemetryData.createAndMarkAsIssued(\r\n    {\r\n      headerRequestId: requestId,\r\n      languageId: doc.languageId,\r\n      source: M_completion_context.completionTypeToString(\r\n        t.completionContext.completionType\r\n      ),\r\n    },\r\n    {\r\n      ...M_telemetry_stuff.telemetrizePromptLength(prompt),\r\n      solutionCount: t.solutionCountTarget,\r\n      promptEndPos: doc.offsetAt(ctxInsertPos),\r\n    }\r\n  );\r\n\r\n  if (\r\n    t.completionContext.completionType ===\r\n    M_completion_context.CompletionType.TODO_QUICK_FIX\r\n  ) {\r\n    const prefixLines = prompt.prefix.split(\"\\n\"),\r\n      lastLine = prefixLines.pop(),\r\n      secondLastLine = prefixLines.pop();\r\n    if (secondLastLine) {\r\n      const match = /^\\W+(todo:?\\s+)/i.exec(secondLastLine);\r\n      if (match) {\r\n        const o = match[1],\r\n          i = secondLastLine.replace(o, \"\");\r\n        prompt.prefix = prefixLines.join(\"\\n\") + \"\\n\" + i + \"\\n\" + lastLine;\r\n      }\r\n    }\r\n  }\r\n\r\n  if (\r\n    t.completionContext.completionType ===\r\n    M_completion_context.CompletionType.UNKNOWN_FUNCTION_QUICK_FIX\r\n  ) {\r\n    prompt.prefix += t.completionContext.prependToCompletion;\r\n  }\r\n\r\n  logger.info(ctx, `prompt: ${JSON.stringify(prompt)}`);\r\n  logger.debug(ctx, `prependToCompletion: ${ctxPrependToCompletion}`);\r\n\r\n  M_telemetry_stuff.telemetry(ctx, \"solution.requested\", t.savedTelemetryData);\r\n\r\n  const blockMode = await ctx\r\n    .get(M_config_stuff.BlockModeConfig)\r\n    .forLanguage(ctx, doc.languageId);\r\n  const isLangSupported = M_get_prompt_parsing_utils_maybe.isSupportedLanguageId(\r\n    doc.languageId\r\n  );\r\n  const contextIndentation = M_context_extractor_from_identation_maybe.contextIndentation(doc, ctxInsertPos);\r\n  const postOptions = {\r\n    stream: !0,\r\n    extra: {\r\n      language: doc.languageId,\r\n      next_indent: null !== (next = contextIndentation.next) && undefined !== next ? next : 0,\r\n    },\r\n  };\r\n  if (\"parsing\" !== blockMode || isLangSupported) {\r\n    postOptions.stop = [\"\\n\\n\", \"\\r\\n\\r\\n\"];\r\n  }\r\n  const repoInfo = M_background_context_provider.extractRepoInfoInBackground(\r\n    ctx,\r\n    doc.fileName\r\n  );\r\n  const request = {\r\n    prompt: prompt,\r\n    languageId: doc.languageId,\r\n    repoInfo: repoInfo,\r\n    ourRequestId: requestId,\r\n    engineUrl: await M_openai_conn_utils.getEngineURL(\r\n      ctx,\r\n      M_background_context_provider.tryGetGitHubNWO(repoInfo),\r\n      doc.languageId,\r\n      M_background_context_provider.getDogFood(repoInfo),\r\n      await M_background_context_provider.getUserKind(ctx),\r\n      t.savedTelemetryData\r\n    ),\r\n    count: t.solutionCountTarget,\r\n    uiKind: M_openai_choices_utils.CopilotUiKind.Panel,\r\n    postOptions: postOptions,\r\n    requestLogProbs: !0,\r\n  };\r\n  \r\n  let F;\r\n  const completionType =\r\n    t.completionContext.completionType ===\r\n    M_completion_context.CompletionType.UNKNOWN_FUNCTION_QUICK_FIX\r\n      ? [\r\n          M_completion_context.CompletionType.UNKNOWN_FUNCTION_QUICK_FIX,\r\n          t.completionContext.prependToCompletion,\r\n        ]\r\n      : t.completionContext.completionType;\r\n\r\n  switch (blockMode) {\r\n    case M_config_stuff.BlockMode.Server:\r\n      F = async (e) => {};\r\n      postOptions.extra.force_indent = null !== (prev = contextIndentation.prev) && undefined !== prev ? prev : -1;\r\n      postOptions.extra.trim_by_indentation = !0;\r\n      break;\r\n    case M_config_stuff.BlockMode.ParsingAndServer:\r\n      F = isLangSupported ? isBlockBodyFinished(ctx, doc, t.startPosition, completionType) : async (e) => {};\r\n      postOptions.extra.force_indent = null !== (w = contextIndentation.prev) && undefined !== w ? w : -1;\r\n      postOptions.extra.trim_by_indentation = !0;\r\n      break;\r\n    case M_config_stuff.BlockMode.Parsing:\r\n    default:\r\n      F = isLangSupported ? isBlockBodyFinished(ctx, doc, t.startPosition, completionType) : async (e) => {};\r\n  }\r\n\r\n  ctx.get(M_status_reporter_maybe.StatusReporter).setProgress();\r\n  const response = await ctx\r\n    .get(M_openai_choices_utils.OpenAIFetcher)\r\n    .fetchAndStreamCompletions(\r\n      ctx,\r\n      request,\r\n      M_telemetry_stuff.TelemetryData.createAndMarkAsIssued(),\r\n      F,\r\n      cancellationToken\r\n    );\r\n  \r\n  if (\"failed\" === response.type || \"canceled\" === response.type) {\r\n    t.reportCancelled();\r\n    ctx.get(M_status_reporter_maybe.StatusReporter).removeProgress();\r\n    return {\r\n      status: \"FinishedWithError\",\r\n      error: `${response.type}: ${response.reason}`,\r\n    };\r\n  }\r\n\r\n  let choices = response.choices;\r\n  choices = (async function* (choices, prependToCompletion) {\r\n    for await (const choice of choices) {\r\n      const choice = {\r\n        ...choice,\r\n      };\r\n      choice.completionText = prependToCompletion + choice.completionText.trimRight();\r\n      yield choice;\r\n    }\r\n  })(choices, ctxPrependToCompletion);\r\n\r\n  if (null !== ctxIndentation) {\r\n    choices = M_openai_choices_utils.cleanupIndentChoices(choices, ctxIndentation);\r\n  }\r\n  choices = M_async_iterable_utils_maybe.asyncIterableMapFilter(choices, async (t) =>\r\n    M_postprocess_choice.postProcessChoice(ctx, \"solution\", doc, ctxInsertPos, t, !1, logger)\r\n  );\r\n\r\n  const choicesProcessor = M_async_iterable_utils_maybe.asyncIterableMapFilter(\r\n    choices,\r\n    async (choice) => {\r\n      let displayText = choice.completionText;\r\n      logger.info(ctx, `Open Copilot completion: [${choice.completionText}]`);\r\n\r\n      if (\r\n        t.completionContext.completionType ===\r\n          M_completion_context.CompletionType.OPEN_COPILOT ||\r\n        t.completionContext.completionType ===\r\n          M_completion_context.CompletionType.TODO_QUICK_FIX\r\n      ) {\r\n        let textBeforeInsertPosSameLine = \"\";\r\n        const nodeStart = await M_context_extractor_from_identation_maybe.getNodeStart(\r\n          ctx,\r\n          doc,\r\n          ctxInsertPos,\r\n          choice.completionText\r\n        );\r\n        if (nodeStart)\r\n          [textBeforeInsertPosSameLine] = M_prompt_extractor.trimLastLine(\r\n            doc.getText(locFactory.range(locFactory.position(nodeStart.line, nodeStart.character), ctxInsertPos))\r\n          );\r\n        else {\r\n          const e = locFactory.position(ctxInsertPos.line, 0);\r\n          textBeforeInsertPosSameLine = doc.getText(locFactory.range(e, ctxInsertPos));\r\n        }\r\n        displayText = textBeforeInsertPosSameLine + displayText;\r\n      }\r\n      let completionText = choice.completionText;\r\n      if (\r\n        t.completionContext.completionType ===\r\n        M_completion_context.CompletionType.TODO_QUICK_FIX\r\n      ) {\r\n        if (doc.lineAt(ctxInsertPos.line).isEmptyOrWhitespace) {\r\n          completionText += \"\\n\";\r\n        }\r\n      }\r\n      if (trailingWs.length > 0 && completionText.startsWith(trailingWs)) {\r\n        completionText = completionText.substring(trailingWs.length);\r\n      }\r\n      const meanLogProb = choice.meanLogProb;\r\n      return {\r\n        displayText: displayText,\r\n        meanProb: undefined !== meanLogProb ? Math.exp(meanLogProb) : 0,\r\n        meanLogProb: meanLogProb || 0,\r\n        completionText: completionText,\r\n        requestId: choice.requestId,\r\n        choiceIndex: choice.choiceIndex,\r\n        prependToCompletion: ctxPrependToCompletion,\r\n      };\r\n    }\r\n  );\r\n\r\n  return solnList(\r\n    ctx.get(M_status_reporter_maybe.StatusReporter),\r\n    cancellationToken,\r\n    choicesProcessor[Symbol.asyncIterator]()\r\n  );\r\n};",
    "3197": "Object.defineProperty(exports, \"__esModule\", {\r\n    value: !0,\r\n  });\r\n  exports.registerGhostText =\r\n    exports.handleGhostTextPostInsert =\r\n    exports.handleGhostTextShown =\r\n    exports.provideInlineCompletions =\r\n    exports.ghostTextLogger =\r\n    exports.getInsertionTextFromCompletion =\r\n      undefined;\r\n  const M_vscode = require(\"vscode\");\r\n  const M_config_stuff = require(\"config-stuff\");\r\n  const M_completion_from_ghost_text = require(\"completion-from-ghost-text\");\r\n  const M_ghost_text_provider = require(\"ghost-text-provider\");\r\n  const M_ghost_text_telemetry = require(\"ghost-text-telemetry\");\r\n  const M_logging_utils = require(\"logging-utils\");\r\n  const M_post_accept_or_reject_tasks = require(\"post-accept-or-reject-tasks\");\r\n  const M_telemetry_stuff = require(\"telemetry-stuff\");\r\n  const M_ignore_document_or_not = require(\"ignore-document-or-not\");\r\n  \r\n  // https://code.visualstudio.com/api/references/vscode-api#InlineCompletionItem\r\n  const postInsertCmdName = \"_ghostTextPostInsert\"; // this command is called after an item is inserted\r\n  \r\n  function getInsertionTextFromCompletion(e) {\r\n    return e.insertText;\r\n  }\r\n  \r\n  // `f` and `m` seem to store state across suggestions\r\n  // unable to completely decipher how they're updated, but\r\n  // f seems to store positions, and m seems to store uri of the\r\n  // document where the completion was shown.\r\n  let f;\r\n  let m;\r\n  \r\n  exports.getInsertionTextFromCompletion = getInsertionTextFromCompletion;\r\n  exports.ghostTextLogger = new M_logging_utils.Logger(\r\n    M_logging_utils.LogLevel.INFO,\r\n    \"ghostText\"\r\n  );\r\n  let shownItemIdx;\r\n  let shownItems = [];\r\n  // this.ctx, doc, pos, completionCtx, cancellationToken\r\n  async function provideInlineCompletions(ctx, doc, pos, completionCtx, cancellationToken) {\r\n    const fn = await (async function (ctx, doc, pos, completionCtx, cancellationToken) {\r\n      const telemetryData = M_telemetry_stuff.TelemetryData.createAndMarkAsIssued();\r\n      // check if inline suggestions are even enabled.\r\n      if (\r\n        !(function (ctx) {\r\n          return M_config_stuff.getConfig(\r\n            ctx,\r\n            M_config_stuff.ConfigKey.InlineSuggestEnable\r\n          );\r\n        })(ctx)\r\n      )\r\n        return {\r\n          type: \"abortedBeforeIssued\",\r\n          reason: \"ghost text is disabled\",\r\n        };\r\n      \r\n      // check if doc should be ignored\r\n      if (M_ignore_document_or_not.ignoreDocument(ctx, doc))\r\n        return {\r\n          type: \"abortedBeforeIssued\",\r\n          reason: \"document is ignored\",\r\n        };\r\n      \r\n      exports.ghostTextLogger.debug(\r\n        ctx,\r\n        `Ghost text called at [${pos.line}, ${pos.character}], with triggerKind ${completionCtx.triggerKind}`\r\n      );\r\n  \r\n      // don't proceed if cancelled already\r\n      if (cancellationToken.isCancellationRequested)\r\n        return (\r\n          exports.ghostTextLogger.info(ctx, \"Cancelled before extractPrompt\"),\r\n          {\r\n            type: \"abortedBeforeIssued\",\r\n            reason: \"cancelled before extractPrompt\",\r\n          }\r\n        );\r\n      \r\n      // nice, I didn't think of this while using copilot\r\n      if (completionCtx.selectedCompletionInfo) {\r\n        exports.ghostTextLogger.debug(\r\n          ctx,\r\n          \"Not showing ghost text because autocomplete widget is displayed\"\r\n        );\r\n        return {\r\n          type: \"abortedBeforeIssued\",\r\n          reason: \"autocomplete widget is displayed\",\r\n        };\r\n      }\r\n  \r\n      // the actual work happens here\r\n      const ghostTextResult = await M_ghost_text_provider.getGhostText(\r\n        ctx,\r\n        doc,\r\n        pos,\r\n        completionCtx.triggerKind === M_vscode.InlineCompletionTriggerKind.Invoke,\r\n        telemetryData,\r\n        cancellationToken\r\n      );\r\n  \r\n      if (\"success\" !== ghostTextResult.type) {\r\n        exports.ghostTextLogger.debug(\r\n          ctx,\r\n          \"Breaking, no results from getGhostText -- \" + ghostTextResult.type + \": \" + ghostTextResult.reason\r\n        );\r\n        return ghostTextResult;\r\n      }\r\n  \r\n      // this b,w is hard to decipher. Need to get back to this.\r\n      const [b, w] = ghostTextResult.value;\r\n      if (\r\n        f &&\r\n        m &&\r\n        (!f.isEqual(pos) || m !== doc.uri) &&\r\n        w !== M_ghost_text_provider.ResultType.TypingAsSuggested\r\n      ) {\r\n        // i THINK what's happening here is if someone continues typing after seeing a suggestion\r\n        // but the typing differs from the suggestion, then some stuff gets\r\n        // sent to telemetry. Will get back to this.\r\n        // my guess is _ contains stuff that's been typed so far....i think???????\r\n        const t = shownItems.flatMap((shownItem) =>\r\n          shownItem.displayText && shownItem.telemetry\r\n            ? [\r\n                {\r\n                  completionText: shownItem.displayText,\r\n                  completionTelemetryData: shownItem.telemetry,\r\n                },\r\n              ]\r\n            : []\r\n        );\r\n        if (t.length > 0) {\r\n          M_post_accept_or_reject_tasks.postRejectionTasks(\r\n            ctx,\r\n            \"ghostText\",\r\n            doc.offsetAt(f),\r\n            m,\r\n            t\r\n          );\r\n        }\r\n      }\r\n      f = pos;\r\n      m = doc.uri;\r\n      shownItems = [];\r\n  \r\n      if (cancellationToken.isCancellationRequested)\r\n        return (\r\n          exports.ghostTextLogger.info(ctx, \"Cancelled after getGhostText\"),\r\n          {\r\n            type: \"canceled\",\r\n            reason: \"after getGhostText\",\r\n            telemetryData: {\r\n              telemetryBlob: ghostTextResult.telemetryBlob,\r\n            },\r\n          }\r\n        );\r\n      \r\n      \r\n      const completions = M_completion_from_ghost_text.completionsFromGhostTextResults(\r\n        ctx,\r\n        b,\r\n        w,\r\n        doc,\r\n        pos,\r\n        (function (e) {\r\n          const t = M_vscode.window.visibleTextEditors.find(\r\n            (t) => t.document === e\r\n          );\r\n          return null == t ? undefined : t.options;\r\n        })(doc),\r\n        shownItemIdx\r\n      );\r\n  \r\n      exports.ghostTextLogger.debug(ctx, \"Completions\", completions);\r\n      \r\n      const inlineCompletionItems = completions.map((completion) => {\r\n        const { text: t, range: o } = completion;\r\n        const i = new M_vscode.Range(\r\n          new M_vscode.Position(o.start.line, o.start.character),\r\n          new M_vscode.Position(o.end.line, o.end.character)\r\n        );\r\n        const item = new M_vscode.InlineCompletionItem(t, i);\r\n        item.index = completion.index;\r\n        item.telemetry = completion.telemetry;\r\n        item.displayText = completion.displayText;\r\n        item.resultType = completion.resultType;\r\n        item.uri = doc.uri;\r\n        item.insertOffset = doc.offsetAt(\r\n          new M_vscode.Position(completion.position.line, completion.position.character)\r\n        );\r\n        // after this item is inserted, the `handleGhostTextPostInsert` will get called\r\n        // because that's the fn registered as callback for `postInsertCmdName`\r\n        item.command = {\r\n          title: \"PostInsertTask\",\r\n          command: postInsertCmdName,\r\n          arguments: [item],\r\n        };\r\n        return item;\r\n      });\r\n  \r\n      return 0 === inlineCompletionItems.length\r\n        ? {\r\n            type: \"empty\",\r\n            reason: \"no completions in final result\",\r\n            telemetryData: ghostTextResult.telemetryData,\r\n          }\r\n        : {\r\n            ...ghostTextResult,\r\n            value: inlineCompletionItems,\r\n          };\r\n    })(ctx, doc, pos, completionCtx, cancellationToken);\r\n    return await M_ghost_text_telemetry.handleGhostTextResultTelemetry(ctx, fn);\r\n  }\r\n  exports.provideInlineCompletions = provideInlineCompletions;\r\n  \r\n  // implements vscode.InlineCompletionItemProvider\r\n  class InlineCompletionItemProvider {\r\n    constructor(e) {\r\n      this.ctx = e;\r\n    }\r\n    // provideInlineCompletionItems(document: TextDocument, position: Position, context: InlineCompletionContext, token: CancellationToken): ProviderResult<InlineCompletionList<T> | T[]>;\r\n    async provideInlineCompletionItems(doc, pos, completionCtx, cancellationToken) {\r\n      return provideInlineCompletions(this.ctx, doc, pos, completionCtx, cancellationToken);\r\n    }\r\n    // undocumented function that gets called by vscode (whenever an item is shown?)\r\n    // found info here: https://github.com/microsoft/vscode/issues/153754\r\n    // https://github.com/juihanamshet1/HandleDidShowCompletionItem-bug/blob/9a48d06b3032b2b5dccc83aedbafeda7fa6d3786/inline-completions/src/extension.ts#L56\r\n    handleDidShowCompletionItem(item) { // item is of type vscode.InlineCompletionItem\r\n      handleGhostTextShown(this.ctx, item);\r\n    }\r\n  }\r\n  \r\n  function handleGhostTextShown(ctx, shownItem) {\r\n    shownItemIdx = shownItem.index;\r\n    if (!shownItems.find((e) => e.index === shownItem.index) &&\r\n          (shownItems.push(shownItem), shownItem.telemetry)) {\r\n      const fromCache = !(shownItem.resultType === M_ghost_text_provider.ResultType.Network);\r\n      \r\n      exports.ghostTextLogger.debug(\r\n        ctx,\r\n        `[${shownItem.telemetry.properties.headerRequestId}] shown choiceIndex: ${shownItem.telemetry.properties.choiceIndex}, fromCache ${fromCache}`\r\n      );\r\n  \r\n        // record which item was shown to you.\r\n        M_ghost_text_telemetry.telemetryShown(\r\n          ctx,\r\n          \"ghostText\",\r\n          shownItem.telemetry,\r\n          fromCache\r\n        );\r\n    }\r\n  }\r\n  \r\n  // this function is called after an item is inserted\r\n  async function handleGhostTextPostInsert(ctx, item) {\r\n    // reset state variables.\r\n    shownItems = [];\r\n    m = undefined;\r\n    f = undefined;\r\n    exports.ghostTextLogger.debug(ctx, \"Ghost text post insert\");\r\n    if (\r\n      item.telemetry &&\r\n      item.uri &&\r\n      item.displayText &&\r\n      undefined !== item.insertOffset &&\r\n      item.range\r\n    ) {\r\n      // record that the item was inserted\r\n      item.telemetry.measurements.compCharLen =\r\n        getInsertionTextFromCompletion(item).length;\r\n      await M_post_accept_or_reject_tasks.postInsertionTasks(\r\n        ctx,\r\n        \"ghostText\",\r\n        item.displayText,\r\n        item.insertOffset,\r\n        item.uri,\r\n        item.telemetry\r\n      );\r\n    }\r\n  }\r\n  \r\n  exports.handleGhostTextShown = handleGhostTextShown;\r\n  exports.handleGhostTextPostInsert = handleGhostTextPostInsert;\r\n  exports.registerGhostText = function (ctx) {\r\n    const t = new InlineCompletionItemProvider(ctx);\r\n    return [\r\n      M_vscode.languages.registerInlineCompletionItemProvider(\r\n        {\r\n          pattern: \"**\",\r\n        },\r\n        t\r\n      ),\r\n      M_vscode.commands.registerCommand(postInsertCmdName, async (item) =>\r\n        handleGhostTextPostInsert(ctx, item)\r\n      ),\r\n    ];\r\n  };\r\n  ",
    "4969": "// prompt-extractor.js\r\nObject.defineProperty(exports, \"__esModule\", {\r\n  value: !0,\r\n});\r\nexports.extractPrompt =\r\n  exports.trimLastLine =\r\n  exports._contextTooShort =\r\n  exports.MIN_PROMPT_CHARS =\r\n    undefined;\r\n\r\nconst M_getPrompt_main_stuff = require(\"getPrompt-main-stuff\");\r\nconst M_config_stuff = require(\"config-stuff\");\r\nconst M_doc_tracker = require(\"doc-tracker\");\r\nconst M_task_maybe = require(\"task\");\r\nconst M_text_doc_relative_path = require(\"text-doc-relative-path\");\r\nconst M_get_prompt_parsing_utils_maybe = require(\"get-prompt-parsing-utils\");\r\nconst M_background_context_provider = require(\"background-context-provider\");\r\n\r\nfunction trimLastLine(str) { // returns [trimmedString, ws]\r\n  const lines = str.split(\"\\n\");\r\n  const lastLine = lines[lines.length - 1];\r\n  const nTrailingWS = lastLine.length - lastLine.trimRight().length;\r\n  const beforeWS = str.slice(0, str.length - nTrailingWS);\r\n  const ws = str.substr(beforeWS.length);\r\n  return [lastLine.length == nTrailingWS ? beforeWS : str, ws];\r\n}\r\n\r\n// (ctx, doc.getText(), doc.offsetAt(insertPos), relativePath, doc.uri, doc.languageId)\r\nasync function getPromptHelper(ctx, docText, insertOffset, docRelPath, docUri, docLangId) {\r\n  var githubNWORaw; // NWO = \"name with owner\", e.g., \"microsoft/vscode\"\r\n  const githubNWO =\r\n    null !==\r\n      (githubNWORaw = M_background_context_provider.tryGetGitHubNWO(\r\n        M_background_context_provider.extractRepoInfoInBackground(ctx, docUri.fsPath)\r\n      )) && undefined !== githubNWORaw\r\n      ? githubNWORaw\r\n      : \"\";\r\n  \r\n  const suffixPercent = await M_config_stuff.suffixPercent(ctx, githubNWO, docLangId);\r\n  const fimSuffixLengthThresh = await M_config_stuff.fimSuffixLengthThreshold(ctx, githubNWO, docLangId);\r\n  // if suffixPercent > 0, then we're in FIM mode, which means the context can be the whole file\r\n  // otherwise, it's everything till the cursor.\r\n  // context size is determined based on the above two conditions.\r\n  if ((suffixPercent > 0 ? docText.length : insertOffset) < exports.MIN_PROMPT_CHARS)\r\n    return exports._contextTooShort;\r\n  \r\n  const now = Date.now();\r\n  const {\r\n    prefix: prefix,\r\n    suffix: suffix,\r\n    promptChoices: promptChoices,\r\n    promptBackground: promptBackground,\r\n    promptElementRanges: promptElementRanges,\r\n  } = await (async function (ctx, docText, insertOffset, docRelPath, docUri, docLangId) {\r\n    var h;\r\n    let relevantDocs = []; // list of atmost 20 other files in the workspace that are of the same language as the current file\r\n    relevantDocs = await (async function (ctx, docFsPath, docLangId) {\r\n      // stores a list of {uri, relativePath, languageId, source} for all OTHER files in the workspace\r\n      // that are of the same language as the current file\r\n      const relevantDocs = [];\r\n\r\n      // sortedTextDocs is a sorted array of all \"text docs known to the editor\"\r\n      // https://code.visualstudio.com/api/references/vscode-api\r\n      const sortedTextDocs = M_doc_tracker.sortByAccessTimes(\r\n        ctx.get(M_text_doc_relative_path.TextDocumentManager).textDocuments\r\n      );\r\n\r\n      let totalSize = 0;\r\n      for (const doc of sortedTextDocs) {\r\n        // if we've already added 20 files, or the total size of all files is > 200k, stop\r\n        if (relevantDocs.length + 1 > 20 || totalSize + doc.getText().length > 2e5) break;\r\n\r\n        if (\"file\" == doc.uri.scheme && doc.fileName !== docFsPath && doc.languageId === docLangId) {\r\n          relevantDocs.push({\r\n            uri: doc.uri.toString(),\r\n            relativePath: await ctx\r\n              .get(M_text_doc_relative_path.TextDocumentManager)\r\n              .getRelativePath(doc), // takes care of edge cases like \"Untitled-1\"\r\n            languageId: doc.languageId,\r\n            source: doc.getText(),\r\n          });\r\n        \r\n          totalSize += doc.getText().length;\r\n        }\r\n      }\r\n      return relevantDocs;\r\n    })(ctx, docUri.fsPath, docLangId);\r\n    \r\n    const thisFile = {\r\n      uri: docUri.toString(),\r\n      source: docText,\r\n      offset: insertOffset,\r\n      relativePath: docRelPath,\r\n      languageId: docLangId,\r\n    };\r\n\r\n    const githubNWO =\r\n      null !==\r\n        (h = M_background_context_provider.tryGetGitHubNWO(\r\n          M_background_context_provider.extractRepoInfoInBackground(ctx, docUri.fsPath)\r\n        )) && undefined !== h\r\n        ? h\r\n        : \"\";\r\n\r\n    let promptOptions = {\r\n      // copilot still uses contextSize = 2048\r\n      maxPromptLength:\r\n        2048 -\r\n        M_config_stuff.getConfig(ctx, M_config_stuff.ConfigKey.SolutionLength),\r\n\r\n      neighboringTabs: await ctx\r\n        .get(M_task_maybe.Features)\r\n        .neighboringTabsOption(githubNWO, docLangId),\r\n\r\n      // one of Cursor, CursorTrimStart, SiblingBlock, SiblingBlockTrimStart\r\n      // (getPrompt-main-stuff)\r\n      suffixStartMode: await ctx.get(M_task_maybe.Features).suffixStartMode(githubNWO, docLangId),\r\n    };\r\n\r\n    const suffixPercent = await M_config_stuff.suffixPercent(ctx, githubNWO, docLangId);\r\n    const suffixMatchThresh = await M_config_stuff.suffixMatchThreshold(ctx, githubNWO, docLangId);\r\n    const fimSuffixLengthThresh = await M_config_stuff.fimSuffixLengthThreshold(ctx, githubNWO, docLangId);\r\n\r\n    if (suffixPercent > 0) {\r\n      promptOptions = {\r\n        ...promptOptions,\r\n        // huh, this one's hardcoded in this version.\r\n        includeSiblingFunctions:\r\n          M_getPrompt_main_stuff.SiblingOption.NoSiblings,\r\n\r\n        suffixPercent: suffixPercent,\r\n        suffixMatchThreshold: suffixMatchThresh,\r\n        fimSuffixLengthThreshold: fimSuffixLengthThresh,\r\n      };\r\n    }\r\n    const fs = ctx.get(M_getPrompt_main_stuff.FileSystem);\r\n    return await M_get_prompt_parsing_utils_maybe.getPrompt(fs, thisFile, promptOptions, relevantDocs);\r\n  })(ctx, docText, insertOffset, docRelPath, docUri, docLangId);\r\n\r\n  const [trimmedPrefix, trailingWs] = trimLastLine(prefix);\r\n  const now2 = Date.now();\r\n\r\n  return {\r\n    type: \"prompt\",\r\n    prompt: {\r\n      prefix: trimmedPrefix,\r\n      suffix: suffix,\r\n      isFimEnabled: suffixPercent > 0 && suffix.length > fimSuffixLengthThresh,\r\n      promptElementRanges: promptElementRanges.ranges,\r\n    },\r\n    trailingWs: trailingWs,\r\n    promptChoices: promptChoices,\r\n    computeTimeMs: now2 - now,\r\n    promptBackground: promptBackground,\r\n  };\r\n}\r\n\r\nasync function getPromptForRegularDoc(ctx, doc, insertPos) {\r\n  const relativePath = await ctx\r\n    .get(M_text_doc_relative_path.TextDocumentManager)\r\n    .getRelativePath(doc);\r\n  return getPromptHelper(ctx, doc.getText(), doc.offsetAt(insertPos), relativePath, doc.uri, doc.languageId);\r\n}\r\n\r\nexports.MIN_PROMPT_CHARS = 10;\r\nexports._contextTooShort = {\r\n  type: \"contextTooShort\",\r\n};\r\n\r\nexports.trimLastLine = trimLastLine;\r\n\r\nexports.extractPrompt = function (ctx, doc, insertPos) {\r\n  const nb = ctx.get(M_text_doc_relative_path.TextDocumentManager).findNotebook(doc);\r\n  return undefined === nb\r\n    ? getPromptForRegularDoc(ctx, doc, insertPos)\r\n    : (async function (ctx, doc, nb, insertPos) {\r\n        const theCell = nb.getCells().find((e) => e.document.uri === doc.uri);\r\n        if (theCell) {\r\n          const beforeCells = nb\r\n            .getCells()\r\n            .filter(\r\n              (e) =>\r\n                e.index < theCell.index &&\r\n                e.document.languageId === theCell.document.languageId\r\n            );\r\n          const beforeCellsCatted =\r\n            beforeCells.length > 0\r\n              ? beforeCells.map((e) => e.document.getText()).join(\"\\n\\n\") + \"\\n\\n\"\r\n              : \"\";\r\n          // wait won't this variable contain duplicate code if doc.getText returns all code?\r\n          // idk the notebook api\r\n          const codeTillThisCell = beforeCellsCatted + doc.getText();\r\n          const l = beforeCellsCatted.length + doc.offsetAt(insertPos);\r\n          const u = await ctx\r\n            .get(M_text_doc_relative_path.TextDocumentManager)\r\n            .getRelativePath(doc);\r\n          return getPromptHelper(ctx, codeTillThisCell, l, u, doc.uri, theCell.document.languageId);\r\n        }\r\n        return getPromptForRegularDoc(ctx, doc, insertPos);\r\n      })(ctx, doc, nb, insertPos);\r\n};\r\n",
    "7017": "Object.defineProperty(exports, \"__esModule\", {\r\n    value: true,\r\n  });\r\n  exports.postInsertionTasks =\r\n    exports.postRejectionTasks =\r\n    exports.captureCode =\r\n      undefined;\r\n  const M_change_tracker = require(\"change-tracker\");\r\n  const M_ghost_text_telemetry = require(\"ghost-text-telemetry\");\r\n  const M_logging_utils = require(\"logging-utils\");\r\n  const M_context_extractor_from_identation_maybe = require(\"context-extractor-from-identation-maybe\");\r\n  const M_prompt_extractor = require(\"prompt-extractor\");\r\n  const M_edit_distance_maybe = require(\"edit-distance\");\r\n  const M_telemetry_stuff = require(\"telemetry-stuff\");\r\n  const M_text_doc_relative_path = require(\"text-doc-relative-path\");\r\n  const d = new M_logging_utils.Logger(\r\n    M_logging_utils.LogLevel.INFO,\r\n    \"post-insertion\"\r\n  );\r\n  // These appear to be different timestamps when the measurements are taken.\r\n  const measurementConfigs = [\r\n    {\r\n      seconds: 15,\r\n      captureCode: false,\r\n      captureRejection: false,\r\n    },\r\n    {\r\n      seconds: 30,\r\n      captureCode: true,\r\n      captureRejection: true,\r\n    },\r\n    {\r\n      seconds: 120,\r\n      captureCode: false,\r\n      captureRejection: false,\r\n    },\r\n    {\r\n      seconds: 300,\r\n      captureCode: false,\r\n      captureRejection: false,\r\n    },\r\n    {\r\n      seconds: 600,\r\n      captureCode: false,\r\n      captureRejection: false,\r\n    },\r\n  ];\r\n  // ctx, docUri, chngTracker.offset\r\n  async function captureCode(ctx, docUri, insertionOffset) {\r\n    const doc = await ctx\r\n      .get(M_text_doc_relative_path.TextDocumentManager)\r\n      .getTextDocument(docUri);\r\n    if (!doc) {\r\n      d.info(\r\n        ctx,\r\n        `Could not get document for ${docUri.fsPath}. Maybe it was closed by the editor.`\r\n      );\r\n      return {\r\n        prompt: {\r\n          prefix: \"\",\r\n          suffix: \"\",\r\n          isFimEnabled: false,\r\n          promptElementRanges: [],\r\n        },\r\n        capturedCode: \"\",\r\n        terminationOffset: 0,\r\n      };\r\n    }\r\n    const docText = doc.getText();\r\n    const prefix = docText.substring(0, insertionOffset);\r\n    const insertionPos = doc.positionAt(insertionOffset);\r\n    // huh - you extract the prompt afresh? interesting. very interesting.\r\n    // so now, instead of \"remembering\" what the original prompt was\r\n    // and therefore \"marking\" that prompt lead/didn't lead to correct\r\n    // completion.......instead of doing that, you're just collecting\r\n    // new training data -- you're saying that at this inspection timestamp,\r\n    // extract prompt that'd be used to complete at the insertion position\r\n    // and we now already have ground truth of this insertion position\r\n    // (stable version of the code after T seconds.)\r\n    //\r\n    // Interesting idea, except this capture-code method gets called\r\n    // just 30s after accept/reject. So...chances are that it was done\r\n    // this way just to not remember the prompt? Who knows.\r\n    const promptWrapper = await M_prompt_extractor.extractPrompt(ctx, doc, insertionPos);\r\n    const prompt =\r\n      \"prompt\" === promptWrapper.type\r\n        ? promptWrapper.prompt\r\n        : {\r\n            prefix: prefix,\r\n            suffix: \"\",\r\n            isFimEnabled: false,\r\n            promptElementRanges: [],\r\n          };\r\n    const suffixAfterInsertion = docText.substring(insertionOffset);\r\n    // absolutely no clue what this context-indentation-from-text thing is.\r\n    // what does the name even mean.\r\n    const f =\r\n      M_context_extractor_from_identation_maybe.contextIndentationFromText(\r\n        prefix,\r\n        insertionOffset,\r\n        doc.languageId\r\n      );\r\n    const m = M_context_extractor_from_identation_maybe.indentationBlockFinished(\r\n      f,\r\n      undefined\r\n    );\r\n    const g = await m(suffixAfterInsertion);\r\n    const _ = Math.min(docText.length, insertionOffset + (g ? 2 * g : 500));\r\n    // but basically looks like it's used to determine how much of the code\r\n    // after the insertion point is relevant for this code completion.\r\n    // because capturedCode is docText.substring(insertionOffset, _)\r\n    return {\r\n      prompt: prompt,\r\n      capturedCode: docText.substring(insertionOffset, _),\r\n      terminationOffset: null != g ? g : -1,\r\n    };\r\n  }\r\n  // docText, displayText, 50, chngTracker.offset\r\n  // docText, displayText, 1500, chngTracker.offset\r\n  // This function appears to compute edit distance between\r\n  // a window around where the suggestion was inserted,\r\n  // and the suggestion itself.\r\n  // not sure why window is considered here exactly.\r\n  // window size is 50 and 1500 resp.\r\n  function f(docText, choiceDisplayText, n, offset) {\r\n    const windowAroundInsertion = docText.substring(\r\n      Math.max(0, offset - n),\r\n      Math.min(docText.length, offset + choiceDisplayText.length + n)\r\n    );\r\n    const i = M_edit_distance_maybe.lexEditDistance(windowAroundInsertion, choiceDisplayText);\r\n    const s = i.lexDistance / i.needleLexLength;\r\n    const { distance: a } = M_edit_distance_maybe.editDistance(\r\n      windowAroundInsertion.substring(i.startOffset, i.endOffset),\r\n      choiceDisplayText\r\n    );\r\n    return {\r\n      relativeLexEditDistance: s,\r\n      charEditDistance: a,\r\n      completionLexLength: i.needleLexLength,\r\n      foundOffset: i.startOffset + Math.max(0, offset - n),\r\n      lexEditDistance: i.lexDistance,\r\n      stillInCodeHeuristic: s <= 0.5 ? 1 : 0,\r\n    };\r\n  }\r\n  exports.captureCode = captureCode;\r\n  exports.postRejectionTasks = function (e, t, n, i, s) {\r\n    s.forEach(({ completionText: n, completionTelemetryData: r }) => {\r\n      d.debug(e, `${t}.rejected choiceIndex: ${r.properties.choiceIndex}`);\r\n      M_ghost_text_telemetry.telemetryRejected(e, t, r);\r\n    });\r\n    const a = new M_change_tracker.ChangeTracker(e, i, n);\r\n    measurementConfigs.filter((e) => e.captureRejection).map((r) => {\r\n      a.push(async () => {\r\n        d.debug(e, `Original offset: ${n}, Tracked offset: ${a.offset}`);\r\n        const { completionTelemetryData: o } = s[0];\r\n        const {\r\n          prompt: c,\r\n          capturedCode: u,\r\n          terminationOffset: p,\r\n        } = await captureCode(e, i, a.offset);\r\n        let f;\r\n        f = c.isFimEnabled\r\n          ? {\r\n              hypotheticalPromptPrefixJson: JSON.stringify(c.prefix),\r\n              hypotheticalPromptSuffixJson: JSON.stringify(c.suffix),\r\n            }\r\n          : {\r\n              hypotheticalPromptJson: JSON.stringify(c.prefix),\r\n            };\r\n        const m = o.extendedBy(\r\n          {\r\n            ...f,\r\n            capturedCodeJson: JSON.stringify(u),\r\n          },\r\n          {\r\n            timeout: r.seconds,\r\n            insertionOffset: n,\r\n            trackedOffset: a.offset,\r\n            terminationOffsetInCapturedCode: p,\r\n          }\r\n        );\r\n        d.debug(\r\n          e,\r\n          `${t}.capturedAfterRejected choiceIndex: ${o.properties.choiceIndex}`,\r\n          m\r\n        );\r\n        M_telemetry_stuff.telemetry(e, t + \".capturedAfterRejected\", m, true);\r\n      }, 1e3 * r.seconds);\r\n    });\r\n  };\r\n  \r\n  // ctx, \"ghostText\", item.displayText, item.insertOffset, item.uri, item.telemetry\r\n  exports.postInsertionTasks = async function (ctx, flow, choiceDisplayText, insertOffset, docUri, telemetry) {\r\n    d.debug(ctx, `${flow}.accepted choiceIndex: ${telemetry.properties.choiceIndex}`);\r\n    M_ghost_text_telemetry.telemetryAccepted(ctx, flow, telemetry);\r\n    const chngTracker = new M_change_tracker.ChangeTracker(ctx, docUri, insertOffset);\r\n    const displayText = choiceDisplayText.trim();\r\n    // set a timeout for every measurement config shown above\r\n    // i.e., after 15s, 30s, 2min, 5min, 10min\r\n    measurementConfigs.map((mConf) =>\r\n      chngTracker.push(\r\n        () =>\r\n          (async function (ctx, flow, displayText, insertOffset, docUri, mConf, telemetry, chngTracker) {\r\n            const doc = await ctx\r\n              .get(M_text_doc_relative_path.TextDocumentManager)\r\n              .getTextDocument(docUri);\r\n            if (doc) {\r\n              const docText = doc.getText();\r\n              let p = f(docText, displayText, 50, chngTracker.offset);\r\n              if (p.stillInCodeHeuristic) {\r\n                p = f(docText, displayText, 1500, chngTracker.offset);\r\n              }\r\n              d.debug(\r\n                ctx,\r\n                `stillInCode: ${\r\n                  p.stillInCodeHeuristic ? \"Found\" : \"Not found\"\r\n                }! Completion '${displayText}' in file ${\r\n                  docUri.fsPath\r\n                }. lexEditDistance fraction was ${\r\n                  p.relativeLexEditDistance\r\n                }. Char edit distance was ${\r\n                  p.charEditDistance\r\n                }. Inserted at ${insertOffset}, tracked at ${chngTracker.offset}, found at ${\r\n                  p.foundOffset\r\n                }. choiceIndex: ${telemetry.properties.choiceIndex}`\r\n              );\r\n              const m = telemetry\r\n                .extendedBy(\r\n                  {},\r\n                  {\r\n                    timeout: mConf.seconds,\r\n                    insertionOffset: insertOffset,\r\n                    trackedOffset: chngTracker.offset,\r\n                  }\r\n                )\r\n                .extendedBy({}, p);\r\n              M_telemetry_stuff.telemetry(ctx, flow + \".stillInCode\", m);\r\n              if (mConf.captureCode) {\r\n                const {\r\n                  prompt: prompt,\r\n                  capturedCode: c,\r\n                  terminationOffset: u,\r\n                } = await captureCode(ctx, docUri, chngTracker.offset);\r\n                let p;\r\n                p = prompt.isFimEnabled\r\n                  ? {\r\n                      hypotheticalPromptPrefixJson: JSON.stringify(prompt.prefix),\r\n                      hypotheticalPromptSuffixJson: JSON.stringify(prompt.suffix),\r\n                    }\r\n                  : {\r\n                      hypotheticalPromptJson: JSON.stringify(prompt.prefix),\r\n                    };\r\n                const f = telemetry.extendedBy(\r\n                  {\r\n                    ...p,\r\n                    capturedCodeJson: JSON.stringify(c),\r\n                  },\r\n                  {\r\n                    timeout: mConf.seconds,\r\n                    insertionOffset: insertOffset,\r\n                    trackedOffset: chngTracker.offset,\r\n                    terminationOffsetInCapturedCode: u,\r\n                  }\r\n                );\r\n                d.debug(\r\n                  ctx,\r\n                  `${flow}.capturedAfterAccepted choiceIndex: ${telemetry.properties.choiceIndex}`,\r\n                  m\r\n                ),\r\n                  (0, M_telemetry_stuff.telemetry)(\r\n                    ctx,\r\n                    flow + \".capturedAfterAccepted\",\r\n                    f,\r\n                    true\r\n                  );\r\n              }\r\n            }\r\n          })(ctx, flow, displayText, insertOffset, docUri, mConf, telemetry, chngTracker),\r\n        1e3 * mConf.seconds\r\n      )\r\n    );\r\n  };\r\n  ",
    "9334": "Object.defineProperty(exports, \"__esModule\", {\r\n    value: !0,\r\n  });\r\n  \r\n  exports.getGhostText =\r\n    exports.completionCache =\r\n    exports.ResultType =\r\n    exports.ghostTextLogger =\r\n      undefined;\r\n  \r\n  const M_getPrompt_main_stuff = require(\"getPrompt-main-stuff\");\r\n  const M_uuid_utils = require(\"uuid-utils\");\r\n  const M_prompt_cache = require(\"prompt-cache\");\r\n  const M_debouncer = require(\"debouncer\");\r\n  const M_async_iterable_utils_maybe = require(\"async-iterable-utils\");\r\n  const M_config_stuff = require(\"config-stuff\");\r\n  const M_task_maybe = require(\"task\");\r\n  const M_logging_utils = require(\"logging-utils\");\r\n  const M_helix_fetcher_and_network_stuff = require(\"helix-fetcher-and-network-stuff\");\r\n  const M_openai_conn_utils = require(\"openai_conn_utils\");\r\n  const M_live_openai_fetcher = require(\"live-openai-fetcher\");\r\n  const M_openai_choices_utils = require(\"openai-choices-utils\");\r\n  const M_status_reporter_maybe = require(\"status-reporter\");\r\n  const M_context_extractor_from_identation_maybe = require(\"context-extractor-from-identation-maybe\");\r\n  const M_prompt_extractor = require(\"prompt-extractor\");\r\n  const M_background_context_provider = require(\"background-context-provider\");\r\n  const M_ghost_text_score_maybe = require(\"ghost-text-score\");\r\n  const M_postprocess_choice = require(\"postprocess-choice\");\r\n  const M_telemetry_stuff = require(\"telemetry-stuff\");\r\n  const M_runtime_mode_maybe = require(\"runtime-mode\");\r\n  const M_location_factory = require(\"location-factory\");\r\n  const M_contextual_filter_manager = require(\"contextual-filter-manager\");\r\n  const M_ghost_text_debouncer_maybe = require(\"ghost-text-debouncer\");\r\n  const M_ghost_text_telemetry = require(\"ghost-text-telemetry\");\r\n  \r\n  var ResultType;\r\n  \r\n  // seems to be like some state variables\r\n  // not fully understood them but it seems like I is used\r\n  // for storing doc from start till the cursor position\r\n  // that's used for detecting if user is \"TypingAsSuggested\"\r\n  // P is storing the last prompt's cache key.\r\n  // but my understanding is murky.\r\n  let I;\r\n  let P;\r\n  \r\n  async function A(e, n, r, o, i, s, a) {\r\n    var u;\r\n    var p;\r\n    var m;\r\n    exports.ghostTextLogger.debug(e, `Getting ${s} from network`);\r\n    r = r.extendedBy();\r\n    const g = await (async function (e, t) {\r\n      const n = await e.get(M_task_maybe.Features).overrideNumGhostCompletions();\r\n      return n\r\n        ? t.isCycling\r\n          ? Math.max(0, 3 - n)\r\n          : n\r\n        : M_config_stuff.shouldDoParsingTrimming(t.blockMode) && t.multiline\r\n        ? M_config_stuff.getConfig(e, M_config_stuff.ConfigKey.InlineSuggestCount)\r\n        : t.isCycling\r\n        ? 2\r\n        : 1;\r\n    })(e, n);\r\n    const _ = M_openai_choices_utils.getTemperatureForSamples(e, g);\r\n    const y = {\r\n      stream: !0,\r\n      n: g,\r\n      temperature: _,\r\n      extra: {\r\n        language: n.languageId,\r\n        next_indent: null !== (u = n.indentation.next) && undefined !== u ? u : 0,\r\n        trim_by_indentation: M_config_stuff.shouldDoServerTrimming(n.blockMode),\r\n      },\r\n    };\r\n    if (n.multiline) {\r\n      y.stop = [\"\\n\"];\r\n    }\r\n    if (n.multiline && n.multiLogitBias) {\r\n      y.logit_bias = {\r\n        50256: -100,\r\n      };\r\n    }\r\n    const v = Date.now();\r\n    const b = {\r\n      endpoint: \"completions\",\r\n      uiKind: M_live_openai_fetcher.CopilotUiKind.GhostText,\r\n      isCycling: JSON.stringify(n.isCycling),\r\n      temperature: JSON.stringify(_),\r\n      n: JSON.stringify(g),\r\n      stop:\r\n        null !== (p = JSON.stringify(y.stop)) && undefined !== p ? p : \"unset\",\r\n      logit_bias: JSON.stringify(\r\n        null !== (m = y.logit_bias) && undefined !== m ? m : null\r\n      ),\r\n    };\r\n    const E = M_telemetry_stuff.telemetrizePromptLength(n.prompt);\r\n    Object.assign(r.properties, b);\r\n    Object.assign(r.measurements, E);\r\n    try {\r\n      const s = {\r\n        prompt: n.prompt,\r\n        languageId: n.languageId,\r\n        repoInfo: n.repoInfo,\r\n        ourRequestId: n.ourRequestId,\r\n        engineUrl: n.engineURL,\r\n        count: g,\r\n        uiKind: M_live_openai_fetcher.CopilotUiKind.GhostText,\r\n        postOptions: y,\r\n      };\r\n      if (n.delayMs > 0) {\r\n        await new Promise((e) => setTimeout(e, n.delayMs));\r\n      }\r\n      const c = await e\r\n        .get(M_live_openai_fetcher.OpenAIFetcher)\r\n        .fetchAndStreamCompletions(e, s, r, i, o);\r\n      return \"failed\" === c.type\r\n        ? {\r\n            type: \"failed\",\r\n            reason: c.reason,\r\n            telemetryData: M_ghost_text_telemetry.mkBasicResultTelemetry(r),\r\n          }\r\n        : \"canceled\" === c.type\r\n        ? (exports.ghostTextLogger.debug(\r\n            e,\r\n            \"Cancelled after awaiting fetchCompletions\"\r\n          ),\r\n          {\r\n            type: \"canceled\",\r\n            reason: c.reason,\r\n            telemetryData: M_ghost_text_telemetry.mkCanceledResultTelemetry(r),\r\n          })\r\n        : a(g, v, c.getProcessingTime(), c.choices);\r\n    } catch (n) {\r\n      if (M_helix_fetcher_and_network_stuff.isAbortError(n))\r\n        return {\r\n          type: \"canceled\",\r\n          reason: \"network request aborted\",\r\n          telemetryData: M_ghost_text_telemetry.mkCanceledResultTelemetry(r, {\r\n            cancelledNetworkRequest: !0,\r\n          }),\r\n        };\r\n      exports.ghostTextLogger.error(e, `Error on ghost text request ${n}`);\r\n      if ((0, M_runtime_mode_maybe.shouldFailForDebugPurposes)(e)) throw n;\r\n      return {\r\n        type: \"failed\",\r\n        reason: \"non-abort error on ghost text request\",\r\n        telemetryData: M_ghost_text_telemetry.mkBasicResultTelemetry(r),\r\n      };\r\n    }\r\n  }\r\n  \r\n  function trimCompletion(choice, opt) {\r\n    const n = {\r\n      ...choice,\r\n    };\r\n    n.completionText = choice.completionText.trimEnd();\r\n    if (opt.forceSingleLine) {\r\n      n.completionText = n.completionText.split(\"\\n\")[0];\r\n    }\r\n    return n;\r\n  }\r\n  \r\n  exports.ghostTextLogger = new M_logging_utils.Logger(\r\n    M_logging_utils.LogLevel.INFO,\r\n    \"ghostText\"\r\n  );\r\n  \r\n  // There seem to be 4 types of Results: Network, Cache, TypingAsSuggested, Cycling\r\n  (function (e) {\r\n    e[(e.Network = 0)] = \"Network\";\r\n    e[(e.Cache = 1)] = \"Cache\";\r\n    e[(e.TypingAsSuggested = 2)] = \"TypingAsSuggested\";\r\n    e[(e.Cycling = 3)] = \"Cycling\";\r\n  })((ResultType = exports.ResultType || (exports.ResultType = {})));\r\n  \r\n  // Cache size is 100 (key is prompt, val is a list of choices)\r\n  // Interestingly, the cache in the CopilotPanel workflow is of size 1e4.\r\n  exports.completionCache = new M_prompt_cache.LRUCache(100);\r\n  \r\n  const debouncer = new M_debouncer.Debouncer();\r\n  \r\n  // just updates the state variables\r\n  function R(e, t) {\r\n    I = e;\r\n    P = t;\r\n  }\r\n  \r\n  // options seems to be of form {multiline: bool, choices: list}\r\n  function cacheCompletion(ctx, promptWrapper, options) {\r\n    const promptCacheKey = M_prompt_cache.keyForPrompt(promptWrapper.prompt);\r\n    const cachedVal = exports.completionCache.get(promptCacheKey);\r\n    if (cachedVal && cachedVal.multiline === options.multiline) {\r\n      exports.completionCache.put(promptCacheKey, {\r\n        multiline: cachedVal.multiline,\r\n        choices: cachedVal.choices.concat(options.choices),\r\n      });\r\n    } else {\r\n      exports.completionCache.put(promptCacheKey, options);\r\n    }\r\n    exports.ghostTextLogger.debug(\r\n      ctx,\r\n      `Appended cached ghost text for key: ${promptCacheKey}, multiline: ${options.multiline}, number of suggestions: ${options.choices.length}`\r\n    );\r\n  }\r\n  \r\n  function getCachedChoices(promptCacheKey, n) {\r\n    const cachedVal = exports.completionCache.get(promptCacheKey);\r\n    if (cachedVal && (!n || cachedVal.multiline))\r\n        return cachedVal.choices;\r\n  }\r\n  \r\n  // not exactly sure what's going on here but seems like some adjustment for whitespaces\r\n  // i think it gets used when user keeps typing as suggestion is shown\r\n  function adjustCompletionForWS(choiceIndex, completionText, trailingWs) {\r\n    if (trailingWs.length > 0) {\r\n      if (completionText.startsWith(trailingWs))\r\n        return {\r\n          completionIndex: choiceIndex,\r\n          completionText: completionText,\r\n          displayText: completionText.substr(trailingWs.length),\r\n          displayNeedsWsOffset: !1,\r\n        };\r\n      {\r\n        const r = completionText.substr(0, completionText.length - completionText.trimLeft().length);\r\n        return trailingWs.startsWith(r)\r\n          ? {\r\n              completionIndex: choiceIndex,\r\n              completionText: completionText,\r\n              displayText: completionText.trimLeft(),\r\n              displayNeedsWsOffset: !0,\r\n            }\r\n          : {\r\n              completionIndex: choiceIndex,\r\n              completionText: completionText,\r\n              displayText: completionText,\r\n              displayNeedsWsOffset: !1,\r\n            };\r\n      }\r\n    }\r\n    return {\r\n      completionIndex: choiceIndex,\r\n      completionText: completionText,\r\n      displayText: completionText,\r\n      displayNeedsWsOffset: !1,\r\n    };\r\n  }\r\n  \r\n  function getExtendedTelemetryObj(ctx, n) {\r\n    const requestId = n.requestId;\r\n    const o = {\r\n      choiceIndex: n.choiceIndex.toString(),\r\n    };\r\n    const i = {\r\n      numTokens: n.numTokens,\r\n      compCharLen: n.completionText.length,\r\n      numLines: n.completionText.split(\"\\n\").length,\r\n    };\r\n    if (n.meanLogProb) {\r\n      i.meanLogProb = n.meanLogProb;\r\n    }\r\n    if (n.meanAlternativeLogProb) {\r\n      i.meanAlternativeLogProb = n.meanAlternativeLogProb;\r\n    }\r\n    const telemetryObj = n.telemetryData.extendedBy(o, i);\r\n    telemetryObj.extendWithRequestId(requestId);\r\n    telemetryObj.measurements.confidence = M_ghost_text_score_maybe.ghostTextScoreConfidence(\r\n      ctx,\r\n      telemetryObj\r\n    );\r\n    telemetryObj.measurements.quantile = M_ghost_text_score_maybe.ghostTextScoreQuantile(\r\n      ctx,\r\n      telemetryObj\r\n    );\r\n    exports.ghostTextLogger.debug(\r\n      ctx,\r\n      `Extended telemetry for ${n.telemetryData.properties.headerRequestId} with retention confidence ${telemetryObj.measurements.confidence} (expected as good or better than about ${telemetryObj.measurements.quantile} of all suggestions)`\r\n    );\r\n    return telemetryObj;\r\n  }\r\n  \r\n  function F(e, t, n, r, o) {\r\n    const i = Date.now() - r;\r\n    const s = i - o;\r\n    const a = n.telemetryData.extendedBy(\r\n      {},\r\n      {\r\n        completionCharLen: n.completionText.length,\r\n        requestTimeMs: i,\r\n        processingTimeMs: o,\r\n        deltaMs: s,\r\n        meanLogProb: n.meanLogProb || NaN,\r\n        meanAlternativeLogProb: n.meanAlternativeLogProb || NaN,\r\n        numTokens: n.numTokens,\r\n      }\r\n    );\r\n    a.extendWithRequestId(n.requestId);\r\n    M_telemetry_stuff.telemetry(e, `ghostText.${t}`, a);\r\n  }\r\n  \r\n  // The main stufffffffffff\r\n  exports.getGhostText = async function (ctx, doc, pos, isCycling, d, cancellationToken) {\r\n    var v;\r\n    var j;\r\n  \r\n    const promptWrapper = await M_prompt_extractor.extractPrompt(ctx, doc, pos);\r\n    if (\"contextTooShort\" === promptWrapper.type) {\r\n      exports.ghostTextLogger.debug(ctx, \"Breaking, not enough context\");\r\n      return {\r\n        type: \"abortedBeforeIssued\",\r\n        reason: \"Not enough context\",\r\n      };\r\n    }\r\n  \r\n    if (null == cancellationToken ? undefined : cancellationToken.isCancellationRequested) {\r\n      exports.ghostTextLogger.info(ctx, \"Cancelled after extractPrompt\");\r\n      return {\r\n        type: \"abortedBeforeIssued\",\r\n        reason: \"Cancelled after extractPrompt\",\r\n      };\r\n    }\r\n    \r\n    // 3 possible values:\r\n    // undefined -- cursor in middle of line, can't insert\r\n    // false -- cursor at end of line (maybe whitespace is there at the end but that's ignored)\r\n    // true -- some brackets/semicolons follow the cursor, but nothing significant.\r\n    const isMiddleOfLine = (function (doc, pos) {\r\n      const hasSuffixOnLine =\r\n        0 != doc.lineAt(pos).text.substr(pos.character).trim().length;\r\n  \r\n      const isSuffixIgnorable = (function (pos, doc) {\r\n        const suffixOnLine = doc.lineAt(pos).text.substr(pos.character).trim();\r\n        return /^\\s*[)}\\]\"'`]*\\s*[:{;,]?\\s*$/.test(suffixOnLine);\r\n      })(pos, doc);\r\n  \r\n      if (!hasSuffixOnLine || isSuffixIgnorable)\r\n          return hasSuffixOnLine && isSuffixIgnorable;\r\n    })(doc, pos);\r\n  \r\n    if (undefined === isMiddleOfLine) {\r\n      exports.ghostTextLogger.debug(ctx, \"Breaking, invalid middle of the line\");\r\n      return {\r\n        type: \"abortedBeforeIssued\",\r\n        reason: \"Invalid middle of the line\",\r\n      };\r\n    }\r\n  \r\n    const statusReporter = ctx.get(M_status_reporter_maybe.StatusReporter);\r\n    const locationFactory = ctx.get(M_location_factory.LocationFactory);\r\n    const requestOptions = await (async function (ctx, doc, pos, promptWrapper, isCycling, isMiddleOfLine) {\r\n      // not really sure what blockmode is...but seems language dependent.\r\n      const blockMode = await ctx\r\n        .get(M_config_stuff.BlockModeConfig)\r\n        .forLanguage(ctx, doc.languageId);\r\n  \r\n      switch (blockMode) {\r\n        case M_config_stuff.BlockMode.Server:\r\n          return {\r\n            blockMode: M_config_stuff.BlockMode.Server,\r\n            requestMultiline: true,\r\n            isCyclingRequest: isCycling,\r\n            finishedCb: async (e) => {},\r\n          };\r\n  \r\n        case M_config_stuff.BlockMode.Parsing:\r\n        case M_config_stuff.BlockMode.ParsingAndServer:\r\n        default: {\r\n          const requestMultiLine = await (async function (ctx, doc, pos, isMiddleOfLine) {\r\n            // huh, interesting. skip multiline if it's a long file?\r\n            if (doc.lineCount >= 8e3) {\r\n              M_telemetry_stuff.telemetry(\r\n                ctx,\r\n                \"ghostText.longFileMultilineSkip\",\r\n                M_telemetry_stuff.TelemetryData.createAndMarkAsIssued({\r\n                  languageId: doc.languageId,\r\n                  lineCount: String(doc.lineCount),\r\n                  currentLine: String(pos.line),\r\n                })\r\n              );\r\n            }\r\n            else {\r\n              if (\r\n                !isMiddleOfLine &&\r\n                M_getPrompt_main_stuff.isSupportedLanguageId(doc.languageId)\r\n              )\r\n                return await M_context_extractor_from_identation_maybe.isEmptyBlockStart(\r\n                  doc,\r\n                  pos\r\n                );\r\n              if (isMiddleOfLine && M_getPrompt_main_stuff.isSupportedLanguageId(doc.languageId))\r\n                return (\r\n                  (await M_context_extractor_from_identation_maybe.isEmptyBlockStart(\r\n                    doc,\r\n                    pos\r\n                  )) ||\r\n                  (await M_context_extractor_from_identation_maybe.isEmptyBlockStart(\r\n                    doc,\r\n                    doc.lineAt(pos).range.end\r\n                  ))\r\n                );\r\n            }\r\n            return false;\r\n          })(ctx, doc, pos, isMiddleOfLine);\r\n          return requestMultiLine\r\n            ? {\r\n                blockMode: blockMode,\r\n                requestMultiline: !0,\r\n                isCyclingRequest: !1,\r\n                finishedCb: async (r) => {\r\n                  // dk what `r` is. tried following calls to isBlockBodyFinished\r\n                  // but it's rather deeply\r\n                  let i;\r\n                  i =\r\n                    promptWrapper.trailingWs.length > 0 &&\r\n                    !promptWrapper.prompt.prefix.endsWith(promptWrapper.trailingWs)\r\n                      ? ctx\r\n                          .get(M_location_factory.LocationFactory)\r\n                          .position(\r\n                            pos.line,\r\n                            Math.max(pos.character - promptWrapper.trailingWs.length, 0)\r\n                          )\r\n                      : pos;\r\n                  return M_context_extractor_from_identation_maybe.isBlockBodyFinished(\r\n                    ctx,\r\n                    doc,\r\n                    i,\r\n                    r\r\n                  );\r\n                },\r\n              }\r\n            : {\r\n                blockMode: blockMode,\r\n                requestMultiline: !1,\r\n                isCyclingRequest: isCycling,\r\n                finishedCb: async (e) => {},\r\n              };\r\n        }\r\n      }\r\n    })(ctx, doc, pos, promptWrapper, isCycling, isMiddleOfLine);\r\n    if (null == cancellationToken ? undefined : cancellationToken.isCancellationRequested) {\r\n      exports.ghostTextLogger.info(ctx, \"Cancelled after requestMultiline\");\r\n      return {\r\n        type: \"abortedBeforeIssued\",\r\n        reason: \"Cancelled after requestMultiline\",\r\n      };\r\n    }\r\n  \r\n    // this looks like all text in doc till the cursor - but that's insane, especially\r\n    // if you consider the following code. Am I getting something wrong?\r\n    const [docTillCursor] = M_prompt_extractor.trimLastLine(\r\n      doc.getText(locationFactory.range(locationFactory.position(0, 0), pos))\r\n    );\r\n  \r\n    // get choices that either match whatever the user's typing\r\n    // otherwise return cached choices - I don't fully understand the details\r\n    // but this is what's being computed roughly\r\n    let choices = (function (ctx, docTillCursor, prompt, requestMultiline) {\r\n      // step1: filter out all cached choices that don't match whatever the user has typed\r\n      const cachedChoicesMatchingTypedText = (function (ctx, docTillCursor, requestMultiline) {\r\n        // I stores the doc till cursor from last \"snapshot\"\r\n        if (!I || !P || !docTillCursor.startsWith(I)) return;\r\n        const cachedChoices = getCachedChoices(P, requestMultiline);\r\n        if (!cachedChoices) return;\r\n        const i = docTillCursor.substring(I.length);\r\n        exports.ghostTextLogger.debug(\r\n          ctx,\r\n          `Getting completions for user-typing flow - remaining prefix: ${i}`\r\n        );\r\n        const updatedChoices = [];\r\n        cachedChoices.forEach((choice) => {\r\n          const trimmedChoice = trimCompletion(choice, {\r\n            forceSingleLine: false,\r\n          });\r\n          if (trimmedChoice.completionText.startsWith(i)) {\r\n            trimmedChoice.completionText = trimmedChoice.completionText.substring(i.length);\r\n            updatedChoices.push(trimmedChoice);\r\n          }\r\n        });\r\n        return updatedChoices;\r\n      })(ctx, docTillCursor, requestMultiline);\r\n  \r\n      if (cachedChoicesMatchingTypedText && cachedChoicesMatchingTypedText.length > 0)\r\n          return [cachedChoicesMatchingTypedText, ResultType.TypingAsSuggested];\r\n      \r\n      const cachedChoices = (function (ctx, n, prompt, requestMultiline) {\r\n        const promptCacheKey = M_prompt_cache.keyForPrompt(prompt);\r\n        exports.ghostTextLogger.debug(\r\n          ctx,\r\n          `Trying to get completions from cache for key: ${promptCacheKey}`\r\n        );\r\n        const cachedChoices = getCachedChoices(promptCacheKey, requestMultiline);\r\n        if (cachedChoices) {\r\n          exports.ghostTextLogger.debug(\r\n            ctx,\r\n            `Got completions from cache for key: ${promptCacheKey}`\r\n          );\r\n          const trimmedChoices = [];\r\n          cachedChoices.forEach((e) => {\r\n            const t = trimCompletion(e, {\r\n              forceSingleLine: !requestMultiline,\r\n            });\r\n            trimmedChoices.push(t);\r\n          });\r\n          // dk why this is there -- all choices would be non-empty ones, right?\r\n          // i think i'm missing something in this code.\r\n          const i = trimmedChoices.filter((e) => e.completionText);\r\n          if (i.length > 0) {\r\n            R(n, promptCacheKey);\r\n          }\r\n          return i;\r\n        }\r\n      })(ctx, docTillCursor, prompt, requestMultiline);\r\n      return cachedChoices && cachedChoices.length > 0 ? [cachedChoices, ResultType.Cache] : undefined;\r\n    })(ctx, docTillCursor, promptWrapper.prompt, requestOptions.requestMultiline);\r\n  \r\n    /* Now it looks like we're making request to the model */\r\n  \r\n    const requestId = M_uuid_utils.v4();\r\n    const repoInfo = M_background_context_provider.extractRepoInfoInBackground(\r\n      ctx,\r\n      doc.fileName\r\n    );\r\n    const engineUrl = await M_openai_conn_utils.getEngineURL(\r\n      ctx,\r\n      M_background_context_provider.tryGetGitHubNWO(repoInfo),\r\n      doc.languageId,\r\n      M_background_context_provider.getDogFood(repoInfo),\r\n      await M_background_context_provider.getUserKind(ctx),\r\n      d\r\n    );\r\n  \r\n    // I'm guessing this controls how long to wait before making request to model?\r\n    const delayMs = await ctx\r\n      .get(M_task_maybe.Features)\r\n      .beforeRequestWaitMs(\r\n        M_background_context_provider.tryGetGitHubNWO(repoInfo) || \"\",\r\n        doc.languageId\r\n      );\r\n  \r\n    // no clue what this parameter is for\r\n    const multiLogitBias = await ctx\r\n      .get(M_task_maybe.Features)\r\n      .multiLogitBias(\r\n        M_background_context_provider.tryGetGitHubNWO(repoInfo) || \"\",\r\n        doc.languageId\r\n      );\r\n  \r\n    const requestPayload = {\r\n      blockMode: requestOptions.blockMode,\r\n      languageId: doc.languageId,\r\n      repoInfo: repoInfo,\r\n      engineURL: engineUrl,\r\n      ourRequestId: requestId,\r\n      prefix: docTillCursor,\r\n      prompt: promptWrapper.prompt,\r\n      multiline: requestOptions.requestMultiline,\r\n      indentation: M_context_extractor_from_identation_maybe.contextIndentation(\r\n        doc,\r\n        pos\r\n      ),\r\n      isCycling: isCycling,\r\n      delayMs: delayMs,\r\n      multiLogitBias: multiLogitBias,\r\n    };\r\n  \r\n    const debouncePredict = await ctx.get(M_task_maybe.Features).debouncePredict();\r\n    const contextualFilterEnabled = await ctx.get(M_task_maybe.Features).contextualFilterEnable();\r\n    const contextualFilterAccThresh = await ctx\r\n      .get(M_task_maybe.Features)\r\n      .contextualFilterAcceptThreshold();\r\n    let ne = false;\r\n    if (debouncePredict || contextualFilterEnabled) {\r\n      ne = true;\r\n    }\r\n    const telemetryObject = (function (ctx, doc, requestPayload, pos, promptWrapper, d, ne) {\r\n      const locFactory = ctx.get(M_location_factory.LocationFactory);\r\n      const lineAtPos = doc.lineAt(pos.line);\r\n      const linePrefix = doc.getText(locFactory.range(lineAtPos.range.start, pos));\r\n      const lineSuffix = doc.getText(locFactory.range(pos, lineAtPos.range.end));\r\n      const d = {\r\n        languageId: doc.languageId,\r\n        beforeCursorWhitespace: JSON.stringify(\"\" === linePrefix.trim()),\r\n        afterCursorWhitespace: JSON.stringify(\"\" === lineSuffix.trim()),\r\n      };\r\n      const p = {\r\n        ...M_telemetry_stuff.telemetrizePromptLength(promptWrapper.prompt),\r\n        promptEndPos: doc.offsetAt(pos),\r\n        documentLength: doc.getText().length,\r\n        delayMs: requestPayload.delayMs,\r\n      };\r\n      const f = d.extendedBy(d, p);\r\n      f.properties.promptChoices = JSON.stringify(promptWrapper.promptChoices, (e, t) =>\r\n        t instanceof Map\r\n          ? Array.from(t.entries()).reduce(\r\n              (e, [t, n]) => ({\r\n                ...e,\r\n                [t]: n,\r\n              }),\r\n              {}\r\n            )\r\n          : t\r\n      );\r\n      f.properties.promptBackground = JSON.stringify(promptWrapper.promptBackground, (e, t) =>\r\n        t instanceof Map ? Array.from(t.values()) : t\r\n      );\r\n      f.measurements.promptComputeTimeMs = promptWrapper.computeTimeMs;\r\n      if (ne) {\r\n        f.measurements.contextualFilterScore =\r\n          M_contextual_filter_manager.contextualFilterScore(ctx, f, promptWrapper.prompt);\r\n      }\r\n      const m = requestPayload.repoInfo;\r\n      f.properties.gitRepoInformation =\r\n        undefined === m\r\n          ? \"unavailable\"\r\n          : m === M_background_context_provider.ComputationStatus.PENDING\r\n          ? \"pending\"\r\n          : \"available\";\r\n      if (\r\n        undefined !== m &&\r\n        m !== M_background_context_provider.ComputationStatus.PENDING\r\n      ) {\r\n        f.properties.gitRepoUrl = m.url;\r\n        f.properties.gitRepoHost = m.hostname;\r\n        f.properties.gitRepoOwner = m.owner;\r\n        f.properties.gitRepoName = m.repo;\r\n        f.properties.gitRepoPath = m.pathname;\r\n      }\r\n      f.properties.engineName = M_live_openai_fetcher.extractEngineName(\r\n        ctx,\r\n        requestPayload.engineURL\r\n      );\r\n      f.properties.isMultiline = JSON.stringify(requestPayload.multiline);\r\n      f.properties.blockMode = requestPayload.blockMode;\r\n      f.properties.isCycling = JSON.stringify(requestPayload.isCycling);\r\n      f.properties.headerRequestId = requestPayload.ourRequestId;\r\n      M_telemetry_stuff.telemetry(ctx, \"ghostText.issued\", f);\r\n      return f;\r\n    })(ctx, doc, requestPayload, pos, promptWrapper, d, ne);\r\n    \r\n    if (\r\n      (requestOptions.isCyclingRequest &&\r\n        (null !== (v = null == choices ? undefined : choices[0].length) && undefined !== v\r\n          ? v\r\n          : 0) > 1) ||\r\n      (!requestOptions.isCyclingRequest && undefined !== choices)\r\n    )\r\n      exports.ghostTextLogger.info(ctx, \"Found inline suggestions locally\");\r\n    else {\r\n      if (null == statusReporter) {\r\n        statusReporter.setProgress();\r\n      }\r\n      if (requestOptions.isCyclingRequest) {\r\n        const n = await (async function (ctx, requestPayload, telemetryObject, cancellationToken, finishedCb) {\r\n          return A(ctx, requestPayload, telemetryObject, cancellationToken, finishedCb, \"all completions\", async (i, s, a, c) => {\r\n            const l = [];\r\n            for await (const n of c) {\r\n              if (null == cancellationToken ? void 0 : cancellationToken.isCancellationRequested)\r\n                return (\r\n                  exports.ghostTextLogger.debug(\r\n                    ctx,\r\n                    \"Cancelled after awaiting choices iterator\"\r\n                  ),\r\n                  {\r\n                    type: \"canceled\",\r\n                    reason: \"after awaiting choices iterator\",\r\n                    telemetryData: (0,\r\n                    M_ghost_text_telemetry.mkCanceledResultTelemetry)(telemetryObject),\r\n                  }\r\n                );\r\n              if (n.completionText.trimEnd()) {\r\n                if (\r\n                  -1 !==\r\n                  l.findIndex(\r\n                    (e) => e.completionText.trim() === n.completionText.trim()\r\n                  )\r\n                )\r\n                  continue;\r\n                l.push(n);\r\n              }\r\n            }\r\n            return (\r\n              l.length > 0 &&\r\n                (cacheCompletion(ctx, requestPayload, {\r\n                  multiline: requestPayload.multiline,\r\n                  choices: l,\r\n                }),\r\n                F(ctx, \"cyclingPerformance\", l[0], s, a)),\r\n              {\r\n                type: \"success\",\r\n                value: l,\r\n                telemetryData: (0, M_ghost_text_telemetry.mkBasicResultTelemetry)(\r\n                  telemetryObject\r\n                ),\r\n                telemetryBlob: telemetryObject,\r\n              }\r\n            );\r\n          });\r\n        })(ctx, requestPayload, telemetryObject, cancellationToken, requestOptions.finishedCb);\r\n        if (\"success\" === n.type) {\r\n          const e =\r\n            null !== (j = null == choices ? void 0 : choices[0]) && void 0 !== j ? j : [];\r\n          n.value.forEach((t) => {\r\n            -1 ===\r\n              e.findIndex(\r\n                (e) => e.completionText.trim() === t.completionText.trim()\r\n              ) && e.push(t);\r\n          }),\r\n            (choices = [e, ResultType.Cycling]);\r\n        } else if (void 0 === choices) return null == statusReporter || statusReporter.removeProgress(), n;\r\n      } else {\r\n        const n = await (0, M_ghost_text_debouncer_maybe.getDebounceLimit)(ctx, telemetryObject);\r\n        try {\r\n          await debouncer.debounce(n);\r\n        } catch {\r\n          return {\r\n            type: \"canceled\",\r\n            reason: \"by debouncer\",\r\n            telemetryData: (0, M_ghost_text_telemetry.mkCanceledResultTelemetry)(\r\n              telemetryObject\r\n            ),\r\n          };\r\n        }\r\n        if (null == cancellationToken ? void 0 : cancellationToken.isCancellationRequested)\r\n          return (\r\n            exports.ghostTextLogger.info(ctx, \"Cancelled during debounce\"),\r\n            {\r\n              type: \"canceled\",\r\n              reason: \"during debounce\",\r\n              telemetryData: (0,\r\n              M_ghost_text_telemetry.mkCanceledResultTelemetry)(telemetryObject),\r\n            }\r\n          );\r\n        if (\r\n          contextualFilterEnabled &&\r\n          telemetryObject.measurements.contextualFilterScore &&\r\n          telemetryObject.measurements.contextualFilterScore < contextualFilterAccThresh / 100\r\n        )\r\n          return (\r\n            exports.ghostTextLogger.info(ctx, \"Cancelled by contextual filter\"),\r\n            {\r\n              type: \"canceled\",\r\n              reason: \"contextualFilterScore below threshold\",\r\n              telemetryData: (0,\r\n              M_ghost_text_telemetry.mkCanceledResultTelemetry)(telemetryObject),\r\n            }\r\n          );\r\n        const r = await (async function (e, n, r, o, s) {\r\n          return A(e, n, r, o, s, \"completions\", async (s, a, c, l) => {\r\n            const u = l[Symbol.asyncIterator](),\r\n              d = await u.next();\r\n            if (d.done)\r\n              return (\r\n                exports.ghostTextLogger.debug(e, \"All choices redacted\"),\r\n                {\r\n                  type: \"empty\",\r\n                  reason: \"all choices redacted\",\r\n                  telemetryData: (0,\r\n                  M_ghost_text_telemetry.mkBasicResultTelemetry)(r),\r\n                }\r\n              );\r\n            if (null == o ? void 0 : o.isCancellationRequested)\r\n              return (\r\n                exports.ghostTextLogger.debug(\r\n                  e,\r\n                  \"Cancelled after awaiting redactedChoices iterator\"\r\n                ),\r\n                {\r\n                  type: \"canceled\",\r\n                  reason: \"after awaiting redactedChoices iterator\",\r\n                  telemetryData: (0,\r\n                  M_ghost_text_telemetry.mkCanceledResultTelemetry)(r),\r\n                }\r\n              );\r\n            const p = d.value;\r\n            if (void 0 === p)\r\n              return (\r\n                exports.ghostTextLogger.debug(\r\n                  e,\r\n                  \"Got undefined choice from redactedChoices iterator\"\r\n                ),\r\n                {\r\n                  type: \"empty\",\r\n                  reason: \"got undefined choice from redactedChoices iterator\",\r\n                  telemetryData: (0,\r\n                  M_ghost_text_telemetry.mkBasicResultTelemetry)(r),\r\n                }\r\n              );\r\n            F(e, \"performance\", p, a, c);\r\n            const h = s - 1;\r\n            exports.ghostTextLogger.debug(\r\n              e,\r\n              `Awaited first result, id:  ${p.choiceIndex}`\r\n            ),\r\n              (function (e, n, r) {\r\n                const o = (0, M_prompt_cache.keyForPrompt)(n.prompt);\r\n                R(n.prefix, o),\r\n                  exports.completionCache.put(o, r),\r\n                  exports.ghostTextLogger.debug(\r\n                    e,\r\n                    `Cached ghost text for key: ${o}, multiline: ${r.multiline}, number of suggestions: ${r.choices.length}`\r\n                  );\r\n              })(e, n, {\r\n                multiline: n.multiline,\r\n                choices: [p],\r\n              });\r\n            const f = [];\r\n            for (let e = 0; e < h; e++) f.push(u.next());\r\n            const m = Promise.all(f).then((r) => {\r\n              exports.ghostTextLogger.debug(\r\n                e,\r\n                `Awaited remaining results, number of results: ${r.length}`\r\n              );\r\n              const o = [];\r\n              for (const n of r) {\r\n                const r = n.value;\r\n                if (\r\n                  void 0 !== r &&\r\n                  (exports.ghostTextLogger.info(\r\n                    e,\r\n                    `GhostText later completion: [${r.completionText}]`\r\n                  ),\r\n                  r.completionText.trimEnd())\r\n                ) {\r\n                  if (\r\n                    -1 !==\r\n                    o.findIndex(\r\n                      (e) => e.completionText.trim() === r.completionText.trim()\r\n                    )\r\n                  )\r\n                    continue;\r\n                  if (r.completionText.trim() === p.completionText.trim())\r\n                    continue;\r\n                  o.push(r);\r\n                }\r\n              }\r\n              o.length > 0 &&\r\n                cacheCompletion(e, n, {\r\n                  multiline: n.multiline,\r\n                  choices: o,\r\n                });\r\n            });\r\n            return (\r\n              (0, M_runtime_mode_maybe.isRunningInTest)(e) && (await m),\r\n              {\r\n                type: \"success\",\r\n                value: trimCompletion(d.value, {\r\n                  forceSingleLine: !1,\r\n                }),\r\n                telemetryData: (0, M_ghost_text_telemetry.mkBasicResultTelemetry)(\r\n                  r\r\n                ),\r\n                telemetryBlob: r,\r\n              }\r\n            );\r\n          });\r\n        })(ctx, requestPayload, telemetryObject, cancellationToken, requestOptions.finishedCb);\r\n        if (\"success\" !== r.type) return null == statusReporter || statusReporter.removeProgress(), r;\r\n        choices = [[r.value], ResultType.Network];\r\n      }\r\n      if (null == statusReporter) {\r\n        statusReporter.removeProgress();\r\n      }\r\n    }\r\n    if (undefined === choices)\r\n      return {\r\n        type: \"failed\",\r\n        reason: \"internal error: choices should be defined after network call\",\r\n        telemetryData: M_ghost_text_telemetry.mkBasicResultTelemetry(telemetryObject),\r\n      };\r\n    const [oe, ie] = choices;\r\n    const se = M_async_iterable_utils_maybe.asyncIterableMapFilter(\r\n      M_async_iterable_utils_maybe.asyncIterableFromArray(oe),\r\n      async (r) =>\r\n        M_postprocess_choice.postProcessChoice(\r\n          ctx,\r\n          \"ghostText\",\r\n          doc,\r\n          pos,\r\n          r,\r\n          isMiddleOfLine,\r\n          exports.ghostTextLogger\r\n        )\r\n    );\r\n    const ae = [];\r\n    for await (const r of se) {\r\n      const o = isMiddleOfLine && M_postprocess_choice.checkSuffix(doc, pos, r);\r\n      if (null == cancellationToken ? undefined : cancellationToken.isCancellationRequested) {\r\n        exports.ghostTextLogger.info(\r\n          ctx,\r\n          \"Cancelled after post processing completions\"\r\n        );\r\n        return {\r\n          type: \"canceled\",\r\n          reason: \"after post processing completions\",\r\n          telemetryData: M_ghost_text_telemetry.mkCanceledResultTelemetry(telemetryObject),\r\n        };\r\n      }\r\n      const i = getExtendedTelemetryObj(ctx, r);\r\n      const a = {\r\n        completion: adjustCompletionForWS(r.choiceIndex, r.completionText, promptWrapper.trailingWs),\r\n        telemetry: i,\r\n        isMiddleOfTheLine: isMiddleOfLine,\r\n        coversSuffix: o,\r\n      };\r\n      ae.push(a);\r\n    }\r\n    return {\r\n      type: \"success\",\r\n      value: [ae, ie],\r\n      telemetryData: M_ghost_text_telemetry.mkBasicResultTelemetry(telemetryObject),\r\n      telemetryBlob: telemetryObject,\r\n    };\r\n  };\r\n  ",
    "3055125": "// neighbor-snippet-selector.js\r\nObject.defineProperty(exports, \"__esModule\", {\r\n  value: !0,\r\n});\r\nexports.getNeighborSnippets = exports.neighborOptionToSelection = undefined;\r\n\r\nconst M_language_marker_constants = require(\"language-marker-constants\");\r\nconst M_jaccard_scorer = require(\"jaccard-scorer\");\r\n\r\nfunction compareThisSnippet(e) {\r\n  return [\r\n    e.relativePath\r\n      ? \"Compare this snippet from \" + e.relativePath + \":\"\r\n      : \"Compare this snippet:\",\r\n  ].concat(e.snippet.split(\"\\n\"));\r\n}\r\n\r\nexports.neighborOptionToSelection = {\r\n  none: {\r\n    matcherFactory: M_jaccard_scorer.FixedWindowSizeJaccardMatcher.FACTORY(1),\r\n    threshold: -1,\r\n    numberOfSnippets: 0,\r\n  },\r\n  conservative: {\r\n    matcherFactory: M_jaccard_scorer.FixedWindowSizeJaccardMatcher.FACTORY(10),\r\n    threshold: 0.3,\r\n    numberOfSnippets: 1,\r\n  },\r\n  medium: {\r\n    matcherFactory: M_jaccard_scorer.FixedWindowSizeJaccardMatcher.FACTORY(20),\r\n    threshold: 0.1,\r\n    numberOfSnippets: 2,\r\n  },\r\n  eager: {\r\n    matcherFactory: M_jaccard_scorer.FixedWindowSizeJaccardMatcher.FACTORY(60),\r\n    threshold: 0,\r\n    numberOfSnippets: 4,\r\n  },\r\n  eagerButLittle: {\r\n    matcherFactory: M_jaccard_scorer.FixedWindowSizeJaccardMatcher.FACTORY(10),\r\n    threshold: 0,\r\n    numberOfSnippets: 1,\r\n  },\r\n};\r\n\r\nexports.getNeighborSnippets = async function (\r\n  curFile,\r\n  relevantDocs,\r\n  neighborTabsOpt,\r\n  indentationMinLengthOpt,\r\n  indentationMaxLengthOpt,\r\n  snippetSelectionOpt,\r\n  snippetSelectionK\r\n) {\r\n  const nbrOpt = exports.neighborOptionToSelection[neighborTabsOpt];\r\n\r\n  // nbrMatchers is an instance of JaccardMatcher (set to compare to curFile)\r\n  const nbrMatcher = (function (\r\n    curFile,\r\n    neighborTabsOpt,\r\n    indentationMinLengthOpt,\r\n    indentationMaxLengthOpt\r\n  ) {\r\n    const nbrOpt = {\r\n      ...exports.neighborOptionToSelection[neighborTabsOpt],\r\n    };\r\n    if (\r\n      undefined !== indentationMinLengthOpt &&\r\n      undefined !== indentationMaxLengthOpt\r\n    ) {\r\n      nbrOpt.matcherFactory =\r\n        M_jaccard_scorer.IndentationBasedJaccardMatcher.FACTORY(\r\n          indentationMinLengthOpt,\r\n          indentationMaxLengthOpt\r\n        );\r\n    }\r\n    return nbrOpt.matcherFactory.to(curFile);\r\n  })(\r\n    curFile,\r\n    neighborTabsOpt,\r\n    indentationMinLengthOpt,\r\n    indentationMaxLengthOpt\r\n  );\r\n\r\n  // go through each relevantDoc and find matches\r\n  return (\r\n    relevantDocs\r\n      // ignore files that are too long or empty\r\n      .filter((e) => e.source.length < 1e4 && e.source.length > 0)\r\n      // select the first 20 files (already sorted by access time)\r\n      .slice(0, 20)\r\n      // search for matches in each file\r\n      .reduce(\r\n        (allMatches, curRelFile) =>\r\n          allMatches.concat(\r\n            // for curRelFile, find matches, and add relativePath to each match\r\n            nbrMatcher\r\n              .findMatches(curRelFile, snippetSelectionOpt, snippetSelectionK)\r\n              .map((e) => ({\r\n                relativePath: curRelFile.relativePath,\r\n                ...e,\r\n              }))\r\n          ),\r\n        []\r\n      )\r\n      // so far, the pipeline has \"allMatches\", which is an array of matches from all files\r\n      // now filter out matches with low scores\r\n      .filter((e) => e.score && e.snippet && e.score > nbrOpt.threshold)\r\n      // sort by score\r\n      .sort((e, t) => e.score - t.score)\r\n      // take the last n matches (the ones with the highest scores)\r\n      .slice(-nbrOpt.numberOfSnippets)\r\n      // format the matches\r\n      .map((t) => ({\r\n        score: t.score,\r\n        snippet: compareThisSnippet(t)\r\n          .map(\r\n            (t) =>\r\n              M_language_marker_constants.comment(t, curFile.languageId) + \"\\n\"\r\n          )\r\n          .join(\"\"),\r\n        startLine: t.startLine,\r\n        endLine: t.endLine,\r\n      }))\r\n  );\r\n};\r\n",
    "3055179": "// imports-and-docs-extractor.js\r\nObject.defineProperty(exports, \"__esModule\", {\r\n    value: !0,\r\n});\r\nexports.extractLocalImportContext = exports.getDocComment = undefined;\r\n\r\nconst M_path = require(\"path\");\r\nconst M_get_prompt_parsing_utils = require(\"get-prompt-parsing-utils\");\r\n\r\nfunction i(e, t) {\r\n    var n;\r\n    let o =\r\n        null === (n = t.namedChild(1)) || undefined === n\r\n            ? undefined\r\n            : n.text.slice(1, -1);\r\n    if (!o || !o.startsWith(\".\")) return null;\r\n    if (\"\" === M_path.extname(o)) o += \".ts\";\r\n    else if (\".ts\" !== M_path.extname(o)) return null;\r\n    return M_path.join(M_path.dirname(e), o);\r\n}\r\n\r\nfunction s(e) {\r\n    var t;\r\n    var n;\r\n    var r;\r\n    var o;\r\n    var i;\r\n    let s = [];\r\n    if (\r\n        \"import_clause\" ===\r\n        (null === (t = e.namedChild(0)) || undefined === t ? undefined : t.type)\r\n    ) {\r\n        let t = e.namedChild(0);\r\n        if (\r\n            \"named_imports\" ===\r\n            (null === (n = null == t ? undefined : t.namedChild(0)) || undefined === n\r\n                ? undefined\r\n                : n.type)\r\n        ) {\r\n            let e = t.namedChild(0);\r\n            for (let t of null !== (r = null == e ? undefined : e.namedChildren) &&\r\n                undefined !== r\r\n                ? r\r\n                : [])\r\n                if (\"import_specifier\" === t.type) {\r\n                    const e =\r\n                        null === (o = t.childForFieldName(\"name\")) || undefined === o\r\n                            ? undefined\r\n                            : o.text;\r\n                    if (e) {\r\n                        const n =\r\n                            null === (i = t.childForFieldName(\"alias\")) || undefined === i\r\n                                ? undefined\r\n                                : i.text;\r\n                        s.push({\r\n                            name: e,\r\n                            alias: n,\r\n                        });\r\n                    }\r\n                }\r\n        }\r\n    }\r\n    return s;\r\n}\r\n\r\nconst a = new Map();\r\n\r\nfunction c(e, t) {\r\n    var n;\r\n    var r;\r\n    let o =\r\n        null !==\r\n            (r =\r\n                null === (n = null == t ? undefined : t.childForFieldName(\"name\")) ||\r\n                    undefined === n\r\n                    ? undefined\r\n                    : n.text) && undefined !== r\r\n            ? r\r\n            : \"\";\r\n    switch (null == t ? undefined : t.type) {\r\n        case \"ambient_declaration\":\r\n            return c(e, t.namedChild(0));\r\n        case \"interface_declaration\":\r\n        case \"enum_declaration\":\r\n        case \"type_alias_declaration\":\r\n            return {\r\n                name: o,\r\n                decl: t.text,\r\n            };\r\n        case \"function_declaration\":\r\n        case \"function_signature\":\r\n            return {\r\n                name: o,\r\n                decl: l(e, t),\r\n            };\r\n        case \"class_declaration\": {\r\n            let n = (function (e, t) {\r\n                let n = t.childForFieldName(\"body\");\r\n                if (n) return n.namedChildren.map((t) => d(e, t)).filter((e) => e);\r\n            })(e, t);\r\n            let r = \"\";\r\n            if (n) {\r\n                let o = t.childForFieldName(\"body\");\r\n                r = `declare ${e.substring(t.startIndex, o.startIndex + 1)}`;\r\n                r += n.map((e) => \"\\n\" + e).join(\"\");\r\n                r += \"\\n}\";\r\n            }\r\n            return {\r\n                name: o,\r\n                decl: r,\r\n            };\r\n        }\r\n    }\r\n    return {\r\n        name: o,\r\n        decl: \"\",\r\n    };\r\n}\r\n\r\nfunction l(e, t) {\r\n    var n;\r\n    var r;\r\n    var o;\r\n    const i =\r\n        null !==\r\n            (r =\r\n                null === (n = t.childForFieldName(\"return_type\")) || undefined === n\r\n                    ? undefined\r\n                    : n.endIndex) && undefined !== r\r\n            ? r\r\n            : null === (o = t.childForFieldName(\"parameters\")) || undefined === o\r\n                ? undefined\r\n                : o.endIndex;\r\n    if (undefined !== i) {\r\n        let n = e.substring(t.startIndex, i) + \";\";\r\n        return \"function_declaration\" === t.type || \"function_signature\" === t.type\r\n            ? \"declare \" + n\r\n            : n;\r\n    }\r\n    return \"\";\r\n}\r\n\r\nfunction getDocComment(e, t) {\r\n    const n = M_get_prompt_parsing_utils.getFirstPrecedingComment(t);\r\n    return n ? e.substring(n.startIndex, t.startIndex) : \"\";\r\n}\r\n\r\nfunction d(e, t) {\r\n    var n;\r\n    var r;\r\n    var i;\r\n    var s;\r\n    var a;\r\n    if (\r\n        \"accessibility_modifier\" ===\r\n        (null === (n = null == t ? undefined : t.firstChild) || undefined === n\r\n            ? undefined\r\n            : n.type) &&\r\n        \"private\" === t.firstChild.text\r\n    )\r\n        return \"\";\r\n    const c = M_get_prompt_parsing_utils.getFirstPrecedingComment(t);\r\n    const p =\r\n        null !==\r\n            (r = (function (e, t) {\r\n                let n = t.startIndex - 1;\r\n                for (; n >= 0 && (\" \" === e[n] || \"\\t\" === e[n]);) n--;\r\n                if (n < 0 || \"\\n\" === e[n]) return e.substring(n + 1, t.startIndex);\r\n            })(e, null != c ? c : t)) && undefined !== r\r\n            ? r\r\n            : \"  \";\r\n    const h = getDocComment(e, t);\r\n    switch (t.type) {\r\n        case \"ambient_declaration\":\r\n            const n = t.namedChild(0);\r\n            return n ? p + h + d(e, n) : \"\";\r\n        case \"method_definition\":\r\n        case \"method_signature\":\r\n            return p + h + l(e, t);\r\n        case \"public_field_definition\": {\r\n            let n =\r\n                null !==\r\n                    (s =\r\n                        null === (i = t.childForFieldName(\"type\")) || undefined === i\r\n                            ? undefined\r\n                            : i.endIndex) && undefined !== s\r\n                    ? s\r\n                    : null === (a = t.childForFieldName(\"name\")) || undefined === a\r\n                        ? undefined\r\n                        : a.endIndex;\r\n            if (undefined !== n) return p + h + e.substring(t.startIndex, n) + \";\";\r\n        }\r\n    }\r\n    return \"\";\r\n}\r\n\r\nasync function p(e, t, n) {\r\n    let r = new Map();\r\n    let i = -1;\r\n    try {\r\n        i = await n.mtime(e);\r\n    } catch {\r\n        return r;\r\n    }\r\n    let s = a.get(e);\r\n    if (s && s.mtime === i) return s.exports;\r\n    if (\"typescript\" === t) {\r\n        let i = null;\r\n        try {\r\n            let s = (await n.readFile(e)).toString();\r\n            i = await M_get_prompt_parsing_utils.parseTree(t, s);\r\n            for (let e of M_get_prompt_parsing_utils.queryExports(t, i.rootNode))\r\n                for (let t of e.captures) {\r\n                    let e = t.node;\r\n                    if (\"export_statement\" === e.type) {\r\n                        let t = e.childForFieldName(\"declaration\");\r\n                        if (null == t ? undefined : t.hasError()) continue;\r\n                        let { name: n, decl: o } = c(s, t);\r\n                        if (n) {\r\n                            o = getDocComment(s, e) + o;\r\n                            let t = r.get(n);\r\n                            if (t) {\r\n                                t = [];\r\n                                r.set(n, t);\r\n                            }\r\n                            t.push(o);\r\n                        }\r\n                    }\r\n                }\r\n        } catch {\r\n        } finally {\r\n            if (i) {\r\n                i.delete();\r\n            }\r\n        }\r\n    }\r\n    if (a.size > 2e3)\r\n        for (let e of a.keys()) {\r\n            a.delete(e);\r\n            if (r.size <= 1e3) break;\r\n        }\r\n    a.set(e, {\r\n        mtime: i,\r\n        exports: r,\r\n    });\r\n    return r;\r\n}\r\n\r\nexports.getDocComment = getDocComment;\r\n\r\nconst h = /^\\s*import\\s*(type|)\\s*\\{[^}]*\\}\\s*from\\s*['\"]\\./gm;\r\n\r\nexports.extractLocalImportContext = async function (e, t) {\r\n    let { source: n, uri: r, languageId: a } = e;\r\n    return t && \"typescript\" === a\r\n        ? (async function (e, t, n) {\r\n            let r = \"typescript\";\r\n            let a = [];\r\n            const c = (function (e) {\r\n                let t;\r\n                let n = -1;\r\n                h.lastIndex = -1;\r\n                do {\r\n                    t = h.exec(e);\r\n                    if (t) {\r\n                        n = h.lastIndex + t.length;\r\n                    }\r\n                } while (t);\r\n                if (-1 === n) return -1;\r\n                const r = e.indexOf(\"\\n\", n);\r\n                return -1 !== r ? r : e.length;\r\n            })(e);\r\n            if (-1 === c) return a;\r\n            e = e.substring(0, c);\r\n            let l = await M_get_prompt_parsing_utils.parseTree(r, e);\r\n            try {\r\n                for (let e of (function (e) {\r\n                    let t = [];\r\n                    for (let n of e.namedChildren)\r\n                        if (\"import_statement\" === n.type) {\r\n                            t.push(n);\r\n                        }\r\n                    return t;\r\n                })(l.rootNode)) {\r\n                    let o = i(t, e);\r\n                    if (!o) continue;\r\n                    let c = s(e);\r\n                    if (0 === c.length) continue;\r\n                    let l = await p(o, r, n);\r\n                    for (let e of c)\r\n                        if (l.has(e.name)) {\r\n                            a.push(...l.get(e.name));\r\n                        }\r\n                }\r\n            } finally {\r\n                l.delete();\r\n            }\r\n            return a;\r\n        })(n, r, t)\r\n        : [];\r\n};\r\n",
    "3055312": "// get-prompt-actual.js\r\nObject.defineProperty(exports, \"__esModule\", {\r\n    value: true,\r\n});\r\nexports.getPrompt =\r\n    exports.newLineEnded =\r\n    exports.normalizeLanguageId =\r\n    exports.PromptOptions =\r\n    exports.SuffixStartMode =\r\n    exports.SuffixMatchOption =\r\n    exports.SuffixOption =\r\n    exports.LineEndingOptions =\r\n    exports.LocalImportContextOption =\r\n    exports.SnippetSelectionOption =\r\n    exports.NeighboringTabsPositionOption =\r\n    exports.NeighboringTabsOption =\r\n    exports.SiblingOption =\r\n    exports.PathMarkerOption =\r\n    exports.LanguageMarkerOption =\r\n    exports.TOKENS_RESERVED_FOR_SUFFIX_ENCODING =\r\n    exports.MAX_EDIT_DISTANCE_LENGTH =\r\n    exports.MAX_PROMPT_LENGTH =\r\n    undefined;\r\nconst M_language_marker_constants = require(\"language-marker-constants\");\r\nconst M_imports_and_docs_extractor = require(\"imports-and-docs-extractor\");\r\nconst M_neighbor_snippet_selector = require(\"neighbor-snippet-selector\");\r\nconst M_sibling_function_fetcher = require(\"sibling-function-fetcher\");\r\nconst M_tokenizer = require(\"tokenizer\");\r\nconst M_prompt_choices_and_wishlist = require(\"prompt-choices-and-wishlist\");\r\nconst M_edit_distance = require(\"edit-distance\");\r\n\r\n// this thing's VERY weird.\r\n// Looks like the getPrompt function remembers the previous used\r\n// suffix, and if the suffix extracted currently is \"roughly\" the same\r\n// then it uses the previous suffix.\r\n// This is some weird caching thing, which idk why it's here.\r\n// Probably the backend model can benefit from cached suffixes?????\r\n// How? I can't imagine how.\r\n// \"roughly the same\" computation is defined by the SuffixMatchOption (Equal/Levenshtein)\r\nlet cachedSuffix = {\r\n    text: \"\",\r\n    tokens: [],\r\n};\r\n\r\nvar LanguageMarkerOption; // NoMarker, Top, Always\r\nvar PathMarkerOption; // NoMarker, Top, Always\r\nvar SiblingOption; // NoSiblings, SiblingsOverContext, ContextOverSiblings\r\nvar NeighboringTabsOption; // None, Conservative, Medium, Eager, EagerButLittle\r\nvar NeighboringTabsPositionOption; // TopOfText, DirectlyAboveCursor, AfterSiblings\r\nvar SnippetSelectionOption; // BestMatch, TopK\r\nvar LocalImportContextOption; // NoContext, Declarations\r\nvar LineEndingOptions; // ConvertToUnix, KeepOriginal\r\nvar SuffixMatchOption; // Equal, Levenshtein\r\nvar SuffixStartMode; // Cursor, CursorTrimStart, SiblingBlock, SiblingBlockTrimStart\r\nvar SuffixOption; // None, FifteenPercent\r\n\r\n// Prompt can only have 1500 tokens\r\nexports.MAX_PROMPT_LENGTH = 1500;\r\n// This variable controls how cached suffix vs current suffix are compared\r\n// if SuffixMatchOption is Levenshtein, then the edit distance is computed\r\n// on the first 50 tokens of the suffix and the cached suffix.\r\n// Again, I find this really weird.\r\nexports.MAX_EDIT_DISTANCE_LENGTH = 50;\r\n// Not sure how this encoding works. Maybe at a parent level when it\r\n// is all converted to a string. Dk if that happens in the extension\r\n// or a backend.\r\nexports.TOKENS_RESERVED_FOR_SUFFIX_ENCODING = 5;\r\n\r\n(function (e) {\r\n    e.NoMarker = \"nomarker\";\r\n    e.Top = \"top\";\r\n    e.Always = \"always\";\r\n})((LanguageMarkerOption = exports.LanguageMarkerOption || (exports.LanguageMarkerOption = {})));\r\n\r\n(function (e) {\r\n    e.NoMarker = \"nomarker\";\r\n    e.Top = \"top\";\r\n    e.Always = \"always\";\r\n})((PathMarkerOption = exports.PathMarkerOption || (exports.PathMarkerOption = {})));\r\n\r\n(function (e) {\r\n    e.NoSiblings = \"nosiblings\";\r\n    e.SiblingsOverContext = \"siblingabove\";\r\n    e.ContextOverSiblings = \"contextabove\";\r\n})((SiblingOption = exports.SiblingOption || (exports.SiblingOption = {})));\r\n\r\n(function (e) {\r\n    e.None = \"none\";\r\n    e.Conservative = \"conservative\";\r\n    e.Medium = \"medium\";\r\n    e.Eager = \"eager\";\r\n    e.EagerButLittle = \"eagerButLittle\";\r\n})((NeighboringTabsOption = exports.NeighboringTabsOption || (exports.NeighboringTabsOption = {})));\r\n\r\n(function (e) {\r\n    e.TopOfText = \"top\";\r\n    e.DirectlyAboveCursor = \"aboveCursor\";\r\n    e.AfterSiblings = \"afterSiblings\";\r\n})(\r\n    (NeighboringTabsPositionOption =\r\n        exports.NeighboringTabsPositionOption ||\r\n        (exports.NeighboringTabsPositionOption = {}))\r\n);\r\n\r\n(function (e) {\r\n    e.BestMatch = \"bestMatch\";\r\n    e.TopK = \"topK\";\r\n})(\r\n    (SnippetSelectionOption = exports.SnippetSelectionOption || (exports.SnippetSelectionOption = {}))\r\n);\r\n\r\n(function (e) {\r\n    e.NoContext = \"nocontext\";\r\n    e.Declarations = \"declarations\";\r\n})(\r\n    (LocalImportContextOption =\r\n        exports.LocalImportContextOption || (exports.LocalImportContextOption = {}))\r\n);\r\n\r\n(function (e) {\r\n    e.ConvertToUnix = \"unix\";\r\n    e.KeepOriginal = \"keep\";\r\n})((LineEndingOptions = exports.LineEndingOptions || (exports.LineEndingOptions = {})));\r\n\r\n(SuffixOption = exports.SuffixOption || (exports.SuffixOption = {})).None = \"none\";\r\nSuffixOption.FifteenPercent = \"fifteenPercent\";\r\n\r\n(function (e) {\r\n    e.Equal = \"equal\";\r\n    e.Levenshtein = \"levenshteineditdistance\";\r\n})((SuffixMatchOption = exports.SuffixMatchOption || (exports.SuffixMatchOption = {})));\r\n\r\n(function (e) {\r\n    e.Cursor = \"cursor\";\r\n    e.CursorTrimStart = \"cursortrimstart\";\r\n    e.SiblingBlock = \"siblingblock\";\r\n    e.SiblingBlockTrimStart = \"siblingblocktrimstart\";\r\n})((SuffixStartMode = exports.SuffixStartMode || (exports.SuffixStartMode = {})));\r\n\r\nclass PromptOptions {\r\n    constructor(fs, kwargs) {\r\n        this.fs = fs;\r\n        this.maxPromptLength = exports.MAX_PROMPT_LENGTH;\r\n        this.languageMarker = LanguageMarkerOption.Top;\r\n        this.pathMarker = PathMarkerOption.Top;\r\n        this.includeSiblingFunctions = SiblingOption.ContextOverSiblings;\r\n        this.localImportContext = LocalImportContextOption.Declarations;\r\n        this.neighboringTabs = NeighboringTabsOption.Eager;\r\n        this.neighboringTabsPosition = NeighboringTabsPositionOption.TopOfText;\r\n        this.lineEnding = LineEndingOptions.ConvertToUnix;\r\n        this.suffixPercent = 0;\r\n        this.suffixStartMode = SuffixStartMode.Cursor;\r\n        this.suffixMatchThreshold = 0;\r\n        this.suffixMatchCriteria = SuffixMatchOption.Levenshtein;\r\n        this.fimSuffixLengthThreshold = 0;\r\n        // override defaults with kwargs\r\n        if (kwargs) for (const e in kwargs) this[e] = kwargs[e];\r\n        if (this.suffixPercent < 0 || this.suffixPercent > 100)\r\n            throw new Error(\r\n                `suffixPercent must be between 0 and 100, but was ${this.suffixPercent}`\r\n            );\r\n        if (this.suffixPercent > 0 && this.includeSiblingFunctions != SiblingOption.NoSiblings)\r\n            throw new Error(\r\n                `Invalid option combination. Cannot set suffixPercent > 0 (${this.suffixPercent}) and includeSiblingFunctions ${this.includeSiblingFunctions}`\r\n            );\r\n        if (this.suffixMatchThreshold < 0 || this.suffixMatchThreshold > 100)\r\n            throw new Error(\r\n                `suffixMatchThreshold must be at between 0 and 100, but was ${this.suffixMatchThreshold}`\r\n            );\r\n        if (this.fimSuffixLengthThreshold < -1)\r\n            throw new Error(\r\n                `fimSuffixLengthThreshold must be at least -1, but was ${this.fimSuffixLengthThreshold}`\r\n            );\r\n        if (\r\n            null != this.indentationMinLength &&\r\n            null != this.indentationMaxLength &&\r\n            this.indentationMinLength > this.indentationMaxLength\r\n        )\r\n            throw new Error(\r\n                `indentationMinLength must be less than or equal to indentationMaxLength, but was ${this.indentationMinLength} and ${this.indentationMaxLength}`\r\n            );\r\n        if (\r\n            this.snippetSelection === SnippetSelectionOption.TopK &&\r\n            undefined === this.snippetSelectionK\r\n        )\r\n            throw new Error(\"snippetSelectionK must be defined.\");\r\n        if (\r\n            this.snippetSelection === SnippetSelectionOption.TopK &&\r\n            this.snippetSelectionK &&\r\n            this.snippetSelectionK <= 0\r\n        )\r\n            throw new Error(\r\n                `snippetSelectionK must be greater than 0, but was ${this.snippetSelectionK}`\r\n            );\r\n    }\r\n}\r\nexports.PromptOptions = PromptOptions;\r\n\r\nconst E = {\r\n    javascriptreact: \"javascript\",\r\n    jsx: \"javascript\",\r\n    typescriptreact: \"typescript\",\r\n    jade: \"pug\",\r\n    cshtml: \"razor\",\r\n};\r\n\r\nfunction normalizeLanguageId(langId) {\r\n    var t;\r\n    langId = langId.toLowerCase();\r\n    return null !== (t = E[langId]) && undefined !== t ? t : langId;\r\n}\r\n\r\n// ensure that the string ends with a newline except for empty strings\r\nfunction newLineEnded(str) {\r\n    return \"\" == str || str.endsWith(\"\\n\") ? str : str + \"\\n\";\r\n}\r\n\r\nexports.normalizeLanguageId = normalizeLanguageId;\r\nexports.newLineEnded = newLineEnded;\r\n\r\n// type of relevantDocs[i] ==> {uri, source, relativePath, languageId}\r\n// type of curFile ==> relevantDocs[i] + {offset}\r\nexports.getPrompt = async function (fs, curFile, promptOpts = {}, relevantDocs = []) {\r\n    var suffixVsCachedSuffixEditDist;\r\n    const promptOptions = new PromptOptions(fs, promptOpts);\r\n    let useCachedSuffix = false;\r\n\r\n    const { source: curSrc, offset: offset } = curFile;\r\n    if (offset < 0 || offset > curSrc.length)\r\n        throw new Error(`Offset ${offset} is out of range.`);\r\n\r\n    curFile.languageId = normalizeLanguageId(curFile.languageId);\r\n    // Priorities is a class with helper methods to create prioritized properties\r\n    const priorities = new M_prompt_choices_and_wishlist.Priorities();\r\n    const beforeCursorPriority = priorities.justBelow(M_prompt_choices_and_wishlist.Priorities.TOP);\r\n    const languageMarkerPriority =\r\n        promptOptions.languageMarker == LanguageMarkerOption.Always\r\n            ? priorities.justBelow(M_prompt_choices_and_wishlist.Priorities.TOP)\r\n            : priorities.justBelow(beforeCursorPriority);\r\n    const pathMarkerPriority =\r\n        promptOptions.pathMarker == PathMarkerOption.Always\r\n            ? priorities.justBelow(M_prompt_choices_and_wishlist.Priorities.TOP)\r\n            : priorities.justBelow(beforeCursorPriority);\r\n    const siblingsPriority =\r\n        promptOptions.includeSiblingFunctions == SiblingOption.ContextOverSiblings\r\n            ? priorities.justBelow(beforeCursorPriority)\r\n            : priorities.justAbove(beforeCursorPriority);\r\n    const localImportPriority = priorities.justBelow(beforeCursorPriority, siblingsPriority);\r\n    const similarSnippetPriority = priorities.justBelow(localImportPriority);\r\n\r\n    // PromptWishlist appears to be a class to which:\r\n    // (a) you add a wishlist of elements you want in the final prompt\r\n    //      along with the priorities you have in mind for each element\r\n    // (b) and at the end it lets you \"fulfill\" the wishlist\r\n    //      based on some constraints (prompt size, priorities)\r\n    const pWishlist = new M_prompt_choices_and_wishlist.PromptWishlist(promptOptions.lineEnding);\r\n    let langMarkerElemIdxs; // indices of language markers in the wishlist\r\n    let pathMarkerElemIdxs; // indices of path markers in the wishlist\r\n\r\n    // if language-marker option is enabled, add current file's language marker\r\n    // to the wishlist\r\n    if (promptOptions.languageMarker != LanguageMarkerOption.NoMarker) {\r\n        // e.g., `#!/usr/bin/env python3` for python, or `Language: \r\n        const e = newLineEnded(M_language_marker_constants.getLanguageMarker(curFile));\r\n        langMarkerElemIdxs = pWishlist.append(\r\n            e,\r\n            M_prompt_choices_and_wishlist.PromptElementKind.LanguageMarker,\r\n            languageMarkerPriority\r\n        );\r\n    }\r\n\r\n    // if path-marker option is enabled, add current file's path marker to the wishlist\r\n    if (promptOptions.pathMarker != PathMarkerOption.NoMarker) {\r\n        const e = newLineEnded(M_language_marker_constants.getPathMarker(curFile));\r\n        if (e.length > 0) {\r\n            pathMarkerElemIdxs = pWishlist.append(\r\n                e,\r\n                M_prompt_choices_and_wishlist.PromptElementKind.PathMarker,\r\n                pathMarkerPriority\r\n            );\r\n        }\r\n    }\r\n\r\n    // if local-import-context option is enabled, add local import context to the wishlist\r\n    if (promptOptions.localImportContext != LocalImportContextOption.NoContext) {\r\n        // at least in current version, this seems to be defined only for typescript\r\n        // and basically that returns a list of imported symbols\r\n        for (const e of await M_imports_and_docs_extractor.extractLocalImportContext(\r\n            curFile,\r\n            promptOptions.fs\r\n        )) {\r\n            pWishlist.append(\r\n                newLineEnded(e),\r\n                M_prompt_choices_and_wishlist.PromptElementKind.ImportedFile,\r\n                localImportPriority\r\n            );\r\n        }\r\n    }\r\n    \r\n    // if neighboringTabs option is enabled and we have relevant docs, collect snippets from\r\n    // those files.\r\n    // This contains the \"Compare this snippet from `path/to/file`:<snip>\" parts of the prompt\r\n    const neighborSnippets =\r\n        promptOptions.neighboringTabs == NeighboringTabsOption.None || 0 == relevantDocs.length\r\n            ? []\r\n            : await M_neighbor_snippet_selector.getNeighborSnippets(\r\n                curFile,\r\n                relevantDocs,\r\n                promptOptions.neighboringTabs,\r\n                promptOptions.indentationMinLength,\r\n                promptOptions.indentationMaxLength,\r\n                promptOptions.snippetSelectionOption,\r\n                promptOptions.snippetSelectionK\r\n            );\r\n    function addSnippetsToWishlist() {\r\n        neighborSnippets.forEach((nbrSnip) =>\r\n            pWishlist.append(\r\n                nbrSnip.snippet,\r\n                M_prompt_choices_and_wishlist.PromptElementKind.SimilarFile,\r\n                similarSnippetPriority,\r\n                M_tokenizer.tokenLength(nbrSnip.snippet),\r\n                nbrSnip.score\r\n            )\r\n        );\r\n    }\r\n    // dk why this condition exists.\r\n    // also dk who sets this option.\r\n    // At least `prompt-extractor.js` (probably the only caller of this function)\r\n    // doesn't set this option. Which means the default value from PromptOptions\r\n    // is used, which is `TopOfText`.\r\n    //\r\n    // tldr: this condition seems to always be true.\r\n    if (promptOptions.neighboringTabsPosition == NeighboringTabsPositionOption.TopOfText) {\r\n        addSnippetsToWishlist();\r\n    }\r\n\r\n    // index in the wishlist of the elements that are of type `BeforeCursor`\r\n    const beforeCursorElemIdxs = [];\r\n    // I'm not sure what this is supposed to mean\r\n    let U;\r\n\r\n    // if sibling-functions option is disabled, `U` is the text before the cursor\r\n    // not sure what U is supposed to mean\r\n    if (promptOptions.includeSiblingFunctions == SiblingOption.NoSiblings) {\r\n        U = curSrc.substring(0, offset);\r\n    }\r\n    // if sibling-functions option is enabled...\r\n    else {\r\n        const {\r\n            siblings: siblings,\r\n            beforeInsertion: beforeInsertion,\r\n            afterInsertion: afterInsertion,\r\n        } = await M_sibling_function_fetcher.getSiblingFunctions(curFile);\r\n\r\n        // appendLineForLine returns indices of the elements it added to the wishlist\r\n        pWishlist.appendLineForLine(\r\n            beforeInsertion,\r\n            M_prompt_choices_and_wishlist.PromptElementKind.BeforeCursor,\r\n            beforeCursorPriority\r\n        ).forEach((e) => beforeCursorElemIdxs.push(e));\r\n        \r\n        let siblingPriority = siblingsPriority;\r\n        siblings.forEach((e) => {\r\n            pWishlist.append(\r\n                e,\r\n                M_prompt_choices_and_wishlist.PromptElementKind.AfterCursor,\r\n                siblingPriority\r\n            );\r\n            // reduce priority for next sibling (coz siblings were sorted, i think by closeness to\r\n            // insertion point)\r\n            siblingPriority = priorities.justBelow(siblingPriority);\r\n        });\r\n        if (promptOptions.neighboringTabsPosition == NeighboringTabsPositionOption.AfterSiblings) {\r\n            addSnippetsToWishlist();\r\n        }\r\n        U = afterInsertion;\r\n    }\r\n\r\n    // dk who sets this option to DirectlyAboveCursor.\r\n    if (promptOptions.neighboringTabsPosition == NeighboringTabsPositionOption.DirectlyAboveCursor) {\r\n        const lastLineIdx = U.lastIndexOf(\"\\n\") + 1;\r\n        const textBeforeLastLine = U.substring(0, lastLineIdx);\r\n        const lastLineText = U.substring(lastLineIdx);\r\n        \r\n        // this is weird.....why would you wanna do this?\r\n        // include stuff in curfile till before the last line\r\n        // then add similar snippets and THEN add the last line?\r\n        // wouldn't it break the flow?\r\n        // i understand the last line needs to be at the end,\r\n        // because model needs to complete that line,\r\n        // but why break the current function...wat.\r\n        // this branch anyway appears to not be used so i guess things are fine\r\n        // but i might be wrong.\r\n        pWishlist.appendLineForLine(\r\n            textBeforeLastLine,\r\n            M_prompt_choices_and_wishlist.PromptElementKind.BeforeCursor,\r\n            beforeCursorPriority\r\n        ).forEach((e) => beforeCursorElemIdxs.push(e));\r\n        addSnippetsToWishlist();\r\n        \r\n        if (lastLineText.length > 0) {\r\n            // also, maybe i've named this variable incorrectly\r\n            // code above made it seem this only contained\r\n            // BeforeCursor elements. but here something else\r\n            // is going on.\r\n            beforeCursorElemIdxs.push(\r\n                pWishlist.append(\r\n                    lastLineText,\r\n                    M_prompt_choices_and_wishlist.PromptElementKind.AfterCursor,\r\n                    beforeCursorPriority\r\n                )\r\n            );\r\n            if (beforeCursorElemIdxs.length > 1) {\r\n                // lol inverse dependency? i really don't get what's happening when nbrTabsOption == DirectlyAboveCursor\r\n                pWishlist.require(beforeCursorElemIdxs[beforeCursorElemIdxs.length - 2], beforeCursorElemIdxs[beforeCursorElemIdxs.length - 1]);\r\n            }\r\n        }\r\n    } else\r\n        pWishlist.appendLineForLine(\r\n            U,\r\n            M_prompt_choices_and_wishlist.PromptElementKind.BeforeCursor,\r\n            beforeCursorPriority\r\n        ).forEach((e) => beforeCursorElemIdxs.push(e));\r\n    \r\n    if (LanguageMarkerOption.Top == promptOptions.languageMarker && beforeCursorElemIdxs.length > 0 && undefined !== langMarkerElemIdxs) {\r\n        // idk why this dependency exists.\r\n        pWishlist.require(langMarkerElemIdxs, beforeCursorElemIdxs[0]);\r\n    }\r\n    if (PathMarkerOption.Top == promptOptions.pathMarker && beforeCursorElemIdxs.length > 0 && undefined !== pathMarkerElemIdxs) {\r\n        // again. why does this dependency exist?\r\n        if (langMarkerElemIdxs) {\r\n            pWishlist.require(pathMarkerElemIdxs, langMarkerElemIdxs);\r\n        } else {\r\n            pWishlist.require(pathMarkerElemIdxs, beforeCursorElemIdxs[0]);\r\n        }\r\n    }\r\n\r\n    if (undefined !== langMarkerElemIdxs && undefined !== pathMarkerElemIdxs) {\r\n        // um. why this anti-dependency? i don't get it. doesn't this contradict the\r\n        // above dependency?\r\n        pWishlist.exclude(pathMarkerElemIdxs, langMarkerElemIdxs);\r\n    }\r\n\r\n    let suffix = curSrc.slice(offset);\r\n    // oh wow, suffix length threshold is a LOWER bound. i thought it was an upper bound.\r\n    if (0 == promptOptions.suffixPercent || suffix.length <= promptOptions.fimSuffixLengthThreshold)\r\n        return pWishlist.fulfill(promptOptions.maxPromptLength);\r\n    \r\n    // a random block. why not.\r\n    // this stuff deals with suffix.\r\n    {\r\n        let suffixOffset = curFile.offset;\r\n        if (\r\n            promptOptions.suffixStartMode !== SuffixStartMode.Cursor &&\r\n            promptOptions.suffixStartMode !== SuffixStartMode.CursorTrimStart\r\n        ) {\r\n            // this function appears to find where the next sibling function starts\r\n            // AFTER the cursor (if no sibling function is found, it returns cursor offset)\r\n            suffixOffset = await M_sibling_function_fetcher.getSiblingFunctionStart(curFile);\r\n        }\r\n\r\n        const budget = promptOptions.maxPromptLength - exports.TOKENS_RESERVED_FOR_SUFFIX_ENCODING;\r\n\r\n        let prefixBudget = Math.floor((budget * (100 - promptOptions.suffixPercent)) / 100);\r\n        let fulfilment = pWishlist.fulfill(prefixBudget);\r\n        // suffixBudget may be greater than budget * suffixPercent / 100\r\n        // because prefixBudget needn't be fully used.\r\n        // i think.\r\n        const suffixBudget = budget - fulfilment.prefixLength;\r\n        \r\n        let suffixText = curSrc.slice(suffixOffset);\r\n        if (\r\n            promptOptions.suffixStartMode != SuffixStartMode.SiblingBlockTrimStart &&\r\n            promptOptions.suffixStartMode != SuffixStartMode.CursorTrimStart\r\n        ) {\r\n            suffixText = suffixText.trimStart();\r\n        }\r\n\r\n        const suffixTokens = M_tokenizer.takeFirstTokens(suffixText, suffixBudget);\r\n        if (suffixTokens.tokens.length <= suffixBudget - 3) {\r\n            // what's this 3?\r\n            prefixBudget = budget - suffixTokens.tokens.length;\r\n            // oh if suffix tokens are less than the suffix budget,\r\n            // we can expand the prefix budget.\r\n            // okay, nice you're greedy, I like that.\r\n            fulfilment = pWishlist.fulfill(prefixBudget);\r\n        }\r\n\r\n        // SuffixMatchOption.Equal means the cached suffix is used\r\n        // if the suffix is EXACTLY equal to the cached suffix.\r\n        if (promptOptions.suffixMatchCriteria == SuffixMatchOption.Equal) {\r\n            if (\r\n                suffixTokens.tokens.length === cachedSuffix.tokens.length &&\r\n                suffixTokens.tokens.every((e, t) => e === cachedSuffix.tokens[t])\r\n            ) {\r\n                useCachedSuffix = true;\r\n            }\r\n        } else {\r\n            // this is the levenshtein distance stuff.\r\n            // also, damn, what a long if statement.\r\n            if (\r\n                promptOptions.suffixMatchCriteria == SuffixMatchOption.Levenshtein &&\r\n                suffixTokens.tokens.length > 0 &&\r\n                promptOptions.suffixMatchThreshold > 0 &&\r\n                100 *\r\n                (null ===\r\n                    (suffixVsCachedSuffixEditDist = M_edit_distance.findEditDistanceScore(\r\n                        suffixTokens.tokens.slice(0, exports.MAX_EDIT_DISTANCE_LENGTH),\r\n                        cachedSuffix.tokens.slice(0, exports.MAX_EDIT_DISTANCE_LENGTH)\r\n                    )) || undefined === suffixVsCachedSuffixEditDist\r\n                    ? undefined\r\n                    : suffixVsCachedSuffixEditDist.score) <\r\n                promptOptions.suffixMatchThreshold *\r\n                Math.min(exports.MAX_EDIT_DISTANCE_LENGTH, suffixTokens.tokens.length)\r\n            ) {\r\n                useCachedSuffix = true;\r\n            }\r\n        }\r\n\r\n        if (true === useCachedSuffix && cachedSuffix.tokens.length <= suffixBudget) {\r\n            if (cachedSuffix.tokens.length <= suffixBudget - 3) {\r\n                // again, recompute prefix budget (in case suffix budget is greater than\r\n                // what's required by suffix)\r\n                prefixBudget = budget - cachedSuffix.tokens.length;\r\n                fulfilment = pWishlist.fulfill(prefixBudget);\r\n            }\r\n            fulfilment.suffix = cachedSuffix.text;\r\n            fulfilment.suffixLength = cachedSuffix.tokens.length;\r\n        } else {\r\n            fulfilment.suffix = suffixTokens.text;\r\n            fulfilment.suffixLength = suffixTokens.tokens.length;\r\n            cachedSuffix = suffixTokens;\r\n        }\r\n        return fulfilment;\r\n    }\r\n};\r\n",
    "3055456": "// prompt-choices-and-wishlist.js\r\nObject.defineProperty(exports, \"__esModule\", {\r\n  value: !0,\r\n});\r\nexports.Priorities =\r\n  exports.PromptWishlist =\r\n  exports.PromptElementRanges =\r\n  exports.PromptChoices =\r\n  exports.PromptBackground =\r\n  exports.PromptElementKind =\r\n  undefined;\r\nconst M_get_prompt_actual = require(\"get-prompt-actual\");\r\nconst M_tokenizer = require(\"tokenizer\");\r\nvar i;\r\n!(function (e) {\r\n  e.BeforeCursor = \"BeforeCursor\";\r\n  e.AfterCursor = \"AfterCursor\";\r\n  e.SimilarFile = \"SimilarFile\";\r\n  e.ImportedFile = \"ImportedFile\";\r\n  e.LanguageMarker = \"LanguageMarker\";\r\n  e.PathMarker = \"PathMarker\";\r\n})((i = exports.PromptElementKind || (exports.PromptElementKind = {})));\r\nclass PromptBackground {\r\n  constructor() {\r\n    this.used = new Map();\r\n    this.unused = new Map();\r\n  }\r\n  markUsed(e) {\r\n    if (this.IsNeighboringTab(e)) {\r\n      this.used.set(e.id, this.convert(e));\r\n    }\r\n  }\r\n  undoMarkUsed(e) {\r\n    if (this.IsNeighboringTab(e)) {\r\n      this.used.delete(e.id);\r\n    }\r\n  }\r\n  markUnused(e) {\r\n    if (this.IsNeighboringTab(e)) {\r\n      this.unused.set(e.id, this.convert(e));\r\n    }\r\n  }\r\n  convert(e) {\r\n    return {\r\n      score: e.score.toFixed(4),\r\n      length: e.text.length,\r\n    };\r\n  }\r\n  IsNeighboringTab(e) {\r\n    return e.kind == i.SimilarFile;\r\n  }\r\n}\r\nexports.PromptBackground = PromptBackground;\r\nclass PromptChoices {\r\n  constructor() {\r\n    this.used = new Map();\r\n    this.unused = new Map();\r\n  }\r\n  markUsed(e) {\r\n    this.used.set(e.kind, (this.used.get(e.kind) || 0) + e.tokens);\r\n  }\r\n  undoMarkUsed(e) {\r\n    this.used.set(e.kind, (this.used.get(e.kind) || 0) - e.tokens);\r\n  }\r\n  markUnused(e) {\r\n    this.unused.set(e.kind, (this.used.get(e.kind) || 0) + e.tokens);\r\n  }\r\n}\r\nexports.PromptChoices = PromptChoices;\r\nclass PromptElementRanges {\r\n  constructor(elems) {\r\n    this.ranges = new Array();\r\n    let lastKind;\r\n    let n = 0;\r\n    for (const { element: elem } of elems)\r\n      if (0 !== elem.text.length) {\r\n        if (lastKind === i.BeforeCursor && elem.kind === i.BeforeCursor) {\r\n          // merge adjacent BeforeCursor elements\r\n          this.ranges[this.ranges.length - 1].end += elem.text.length;\r\n        } else {\r\n          // add a new range otherwise\r\n          this.ranges.push({\r\n            kind: elem.kind,\r\n            start: n,\r\n            end: n + elem.text.length,\r\n          });\r\n        }\r\n        lastKind = elem.kind;\r\n        n += elem.text.length;\r\n      }\r\n  }\r\n}\r\nexports.PromptElementRanges = PromptElementRanges;\r\nexports.PromptWishlist = class {\r\n  constructor(e) {\r\n    this.content = [];\r\n    this.lineEndingOption = e;\r\n  }\r\n  \r\n  getContent() {\r\n    return [...this.content];\r\n  }\r\n\r\n  convertLineEndings(text) {\r\n    if (\r\n      this.lineEndingOption ===\r\n      M_get_prompt_actual.LineEndingOptions.ConvertToUnix\r\n    ) {\r\n      text = text.replace(/\\r\\n/g, \"\\n\").replace(/\\r/g, \"\\n\");\r\n    }\r\n    return text;\r\n  }\r\n\r\n  append(text, kind, priority, nTokens = M_tokenizer.tokenLength(text), score = NaN) {\r\n    text = this.convertLineEndings(text);\r\n    const idx = this.content.length;\r\n    this.content.push({\r\n      id: idx,\r\n      text: text,\r\n      kind: kind,\r\n      priority: priority,\r\n      tokens: nTokens,\r\n      requires: [],\r\n      excludes: [],\r\n      score: score,\r\n    });\r\n    return idx;\r\n  }\r\n\r\n  appendLineForLine(text, kind, priority) {\r\n    const lines = (text = this.convertLineEndings(text)).split(\"\\n\");\r\n    for (let i = 0; i < lines.length - 1; i++) lines[i] += \"\\n\";\r\n\r\n    // merge double newlines\r\n    const lines2 = [];\r\n    lines.forEach((line, i) => {\r\n      if (\"\\n\" === line && lines2.length > 0 && !lines2[lines2.length - 1].endsWith(\"\\n\\n\")) {\r\n        lines2[lines2.length - 1] += \"\\n\";\r\n      } else {\r\n        lines2.push(line);\r\n      }\r\n    });\r\n\r\n    const insertIdxs = [];\r\n    lines2.forEach((line, lineNo) => {\r\n      if (\"\" !== line) {\r\n        insertIdxs.push(this.append(line, kind, priority));\r\n        if (lineNo > 0) {\r\n          // require the previous line\r\n          this.content[this.content.length - 2].requires = [\r\n            this.content[this.content.length - 1],\r\n          ];\r\n        }\r\n      }\r\n    });\r\n\r\n    return insertIdxs;\r\n  }\r\n\r\n  require(idx1, idx2) {\r\n    const el1 = this.content.find((t) => t.id === idx1);\r\n    const el2 = this.content.find((e) => e.id === idx2);\r\n    if (el1 && el2) {\r\n      el1.requires.push(el2);\r\n    }\r\n  }\r\n\r\n  exclude(idx1, idx2) {\r\n    const el1 = this.content.find((t) => t.id === idx1);\r\n    const el2 = this.content.find((e) => e.id === idx2);\r\n    if (el1 && el2) {\r\n      el1.excludes.push(el2);\r\n    }\r\n  }\r\n\r\n  fulfill(tokenBudget) {\r\n    // fulfill the wishlist given a token budget\r\n\r\n    const promptChoices = new PromptChoices();\r\n    const promptBackground = new PromptBackground();\r\n    const wishlist = this.content.map((elem, idx) => ({\r\n      element: elem,\r\n      index: idx,\r\n    }));\r\n\r\n    // sort by (priority, index)\r\n    wishlist.sort((e, t) =>\r\n      e.element.priority === t.element.priority\r\n        ? t.index - e.index\r\n        : t.element.priority - e.element.priority\r\n    );\r\n\r\n    // sets of included and excluded indices\r\n    const included = new Set();\r\n    const excluded = new Set();\r\n    let firstOutOfBudgetElem; // the first element that is out of budget\r\n                              // keeping track of this because:\r\n                              // sum(len(elem.tokens) for elem in elems) >= sum(len(tokenize(cat(elem.text for elem in elems)))\r\n                              // and the loop checks number of consumed tokens using the equation on the left,\r\n                              // which is an overestimate of actual number of tokens (on the right)\r\n                              // so we remember which was the almost-included element,\r\n                              // concat all text of included and this element, see if we're under budget\r\n                              // if so, we can get a tiny bit of more information in the prompt.\r\n                              // i really don't know how much benefit this can provide,\r\n                              // but interesting to think about. lol.\r\n    const addedElems = []; // same as included, but sorted, and with elements, i.e., [{element, index}, ...]\r\n    let availableTokens = tokenBudget;\r\n\r\n    wishlist.forEach((elemWithIdx) => {\r\n      var followingElemWithIdx;\r\n      const elem = elemWithIdx.element;\r\n      const idx = elemWithIdx.index;\r\n\r\n      if (\r\n        availableTokens >= 0 &&\r\n        (availableTokens > 0 || undefined === firstOutOfBudgetElem) &&\r\n        elem.requires.every((e) => included.has(e.id)) &&\r\n        !excluded.has(elem.id)\r\n      ) {\r\n        let nTokens = elem.tokens;\r\n        // oof, crazy obfuscated code\r\n        const followingElem =\r\n          null ===\r\n            (followingElemWithIdx = (function (addedElems, idx) {\r\n              let followingElemWithIdx;\r\n              let minIdx = 1 / 0;\r\n              for (const addedElem of addedElems)\r\n                if (addedElem.index > idx && addedElem.index < minIdx) {\r\n                  followingElemWithIdx = addedElem;\r\n                  minIdx = addedElem.index;\r\n                }\r\n              return followingElemWithIdx;\r\n            })(addedElems, idx)) || undefined === followingElemWithIdx\r\n            ? undefined\r\n            : followingElemWithIdx.element;\r\n        \r\n        // some edge case handling about token computation and whitespaces.\r\n        if (elem.text.endsWith(\"\\n\\n\") && followingElem && !followingElem.text.match(/^\\s/)) {\r\n          nTokens++;\r\n        }\r\n\r\n        if (availableTokens >= nTokens) {\r\n          availableTokens -= nTokens;\r\n          included.add(elem.id);\r\n          elem.excludes.forEach((e) => excluded.add(e.id));\r\n          promptChoices.markUsed(elem);\r\n          promptBackground.markUsed(elem);\r\n          addedElems.push(elemWithIdx);\r\n        } else {\r\n          firstOutOfBudgetElem = null != firstOutOfBudgetElem ? firstOutOfBudgetElem : elemWithIdx;\r\n        }\r\n      } else {\r\n        promptChoices.markUnused(elem);\r\n        promptBackground.markUnused(elem);\r\n      }\r\n    });\r\n\r\n    // even though we process elements by priority, the prompt is generated\r\n    // after sorting by index, so that the order of elements is preserved\r\n    addedElems.sort((e, t) => e.index - t.index);\r\n    \r\n    let prefix = addedElems.reduce((result, cur) => result + cur.element.text, \"\");\r\n    let prefixLen = M_tokenizer.tokenLength(prefix);\r\n    \r\n    // while we're exceeding the token budget, remove the last element\r\n    for (; prefixLen > tokenBudget;) {\r\n      // sort by (priority, index)\r\n      addedElems.sort((e, t) =>\r\n        t.element.priority === e.element.priority\r\n          ? t.index - e.index\r\n          : t.element.priority - e.element.priority\r\n      );\r\n\r\n      const lastImpElem = addedElems.pop();\r\n      if (lastImpElem) {\r\n        // if we remove this, shouldn't we also respect its requires and excludes?\r\n        // doesn't look like that's happening here\r\n        promptChoices.undoMarkUsed(lastImpElem.element);\r\n        promptChoices.markUnused(lastImpElem.element);\r\n        promptBackground.undoMarkUsed(lastImpElem.element);\r\n        promptBackground.markUnused(lastImpElem.element);\r\n        firstOutOfBudgetElem = undefined;\r\n      }\r\n\r\n      addedElems.sort((e, t) => e.index - t.index);\r\n      prefix = addedElems.reduce((e, t) => e + t.element.text, \"\");\r\n      prefixLen = M_tokenizer.tokenLength(prefix);\r\n    }\r\n\r\n    // why do we need to copy this?\r\n    const addedElemsCopy = [...addedElems];\r\n    \r\n    // if we almost included an element, but didn't because we ran out of budget,\r\n    // recompute the number of tokens more precisely\r\n    if (undefined !== firstOutOfBudgetElem) {\r\n      addedElemsCopy.push(firstOutOfBudgetElem);\r\n      addedElemsCopy.sort((e, t) => e.index - t.index);\r\n      \r\n      const prefix = addedElemsCopy.reduce((e, t) => e + t.element.text, \"\");\r\n      const prefixLen = M_tokenizer.tokenLength(prefix);\r\n      \r\n      if (prefixLen <= tokenBudget) {\r\n        // yay, we squeezed in a tiny bit more information\r\n        promptChoices.markUsed(firstOutOfBudgetElem.element);\r\n        promptBackground.markUsed(firstOutOfBudgetElem.element);\r\n        const promptElemRngs = new PromptElementRanges(addedElemsCopy);\r\n        \r\n        return {\r\n          prefix: prefix,\r\n          suffix: \"\",\r\n          prefixLength: prefixLen,\r\n          suffixLength: 0,\r\n          promptChoices: promptChoices,\r\n          promptBackground: promptBackground,\r\n          promptElementRanges: promptElemRngs,\r\n        };\r\n      }\r\n      promptChoices.markUnused(firstOutOfBudgetElem.element);\r\n      promptBackground.markUnused(firstOutOfBudgetElem.element);\r\n    }\r\n\r\n    const promptElemRngs = new PromptElementRanges(addedElems);\r\n    return {\r\n      prefix: prefix,\r\n      suffix: \"\",\r\n      prefixLength: prefixLen,\r\n      suffixLength: 0,\r\n      promptChoices: promptChoices,\r\n      promptBackground: promptBackground,\r\n      promptElementRanges: promptElemRngs,\r\n    };\r\n  }\r\n};\r\n\r\nclass Priorities {\r\n  constructor() {\r\n    this.registeredPriorities = [0, 1];\r\n  }\r\n  register(e) {\r\n    if (e > Priorities.TOP || e < Priorities.BOTTOM)\r\n      throw new Error(\"Priority must be between 0 and 1\");\r\n    this.registeredPriorities.push(e);\r\n    return e;\r\n  }\r\n  justAbove(...e) {\r\n    const t = Math.max(...e);\r\n    const n = Math.min(...this.registeredPriorities.filter((e) => e > t));\r\n    return this.register((n + t) / 2);\r\n  }\r\n  justBelow(...e) {\r\n    const t = Math.min(...e);\r\n    const n = Math.max(...this.registeredPriorities.filter((e) => e < t));\r\n    return this.register((n + t) / 2);\r\n  }\r\n  between(e, t) {\r\n    if (\r\n      this.registeredPriorities.some((n) => n > e && n < t) ||\r\n      !this.registeredPriorities.includes(e) ||\r\n      !this.registeredPriorities.includes(t)\r\n    )\r\n      throw new Error(\"Priorities must be adjacent in the list of priorities\");\r\n    return this.register((e + t) / 2);\r\n  }\r\n}\r\nexports.Priorities = Priorities;\r\nPriorities.TOP = 1;\r\nPriorities.BOTTOM = 0;\r\n",
    "3055670": "// sibling-function-fetcher\r\nObject.defineProperty(exports, \"__esModule\", {\r\n  value: !0,\r\n});\r\nexports.getSiblingFunctionStart = exports.getSiblingFunctions = undefined;\r\n\r\nconst M_get_prompt_actual = require(\"get-prompt-actual\");\r\nconst M_get_prompt_parsing_utils = require(\"get-prompt-parsing-utils\");\r\n\r\nexports.getSiblingFunctions = async function ({\r\n  source: source,\r\n  offset: offset,\r\n  languageId: languageId,\r\n}) {\r\n  var i;\r\n  var s;\r\n  const siblings = [];\r\n  let beforeInsertion = \"\";\r\n  let afterInsertion = source.substring(0, offset);\r\n\r\n  if (M_get_prompt_parsing_utils.isSupportedLanguageId(languageId)) {\r\n    const parseTree = await M_get_prompt_parsing_utils.parseTree(languageId, source);\r\n    try {\r\n      let idx = offset;\r\n      for (; idx >= 0 && /\\s/.test(source[idx]);)\r\n        idx--;\r\n      const curDescendent = parseTree.rootNode.descendantForIndex(idx);\r\n      const ancestor = M_get_prompt_parsing_utils.getAncestorWithSiblingFunctions(\r\n        languageId,\r\n        curDescendent\r\n      );\r\n      if (ancestor) {\r\n        const firstComment = M_get_prompt_parsing_utils.getFirstPrecedingComment(ancestor);\r\n        // either firstComment.startIndex or ancestor.startIndex\r\n        const startIdx =\r\n          null !== (i = null == firstComment ? undefined : firstComment.startIndex) && undefined !== i\r\n            ? i\r\n            : ancestor.startIndex;\r\n        let p;\r\n        let f = 0;\r\n        for (; \" \" == (p = source[startIdx - f - 1]) || \"\\t\" == p;) f++;\r\n        const ws = source.substring(startIdx - f, startIdx); // whitespace (i think)\r\n\r\n        for (let sibling = ancestor.nextSibling; sibling; sibling = sibling.nextSibling)\r\n          if (M_get_prompt_parsing_utils.isFunctionDefinition(languageId, sibling)) {\r\n            const comment = M_get_prompt_parsing_utils.getFirstPrecedingComment(sibling);\r\n            // either comment.startIndex or sibling.startIndex\r\n            const startIdx =\r\n              null !== (s = null == comment ? undefined : comment.startIndex) &&\r\n                undefined !== s\r\n                ? s\r\n                : sibling.startIndex;\r\n            // what. wouldn't startIdx always be less than offset?\r\n            if (startIdx < offset) continue;\r\n            const siblingSrc = source.substring(startIdx, sibling.endIndex);\r\n            const siblingSrc2 = M_get_prompt_actual.newLineEnded(siblingSrc) + \"\\n\" + ws;\r\n            siblings.push(siblingSrc2);\r\n          }\r\n        beforeInsertion = source.substring(0, startIdx);\r\n        afterInsertion = source.substring(startIdx, offset);\r\n      }\r\n    } finally {\r\n      parseTree.delete();\r\n    }\r\n  }\r\n\r\n  return {\r\n    siblings: siblings,\r\n    beforeInsertion: beforeInsertion,\r\n    afterInsertion: afterInsertion,\r\n  };\r\n};\r\nexports.getSiblingFunctionStart = async function ({\r\n  source: source,\r\n  offset: offset,\r\n  languageId: languageId,\r\n}) {\r\n  var r;\r\n  if (M_get_prompt_parsing_utils.isSupportedLanguageId(languageId)) {\r\n    const parseTree = await M_get_prompt_parsing_utils.parseTree(languageId, source);\r\n    try {\r\n      let idx = offset;\r\n      for (; idx >= 0 && /\\s/.test(source[idx]);)\r\n        idx--;\r\n\r\n      const desc = parseTree.rootNode.descendantForIndex(idx);\r\n      const ancestor = M_get_prompt_parsing_utils.getAncestorWithSiblingFunctions(\r\n        languageId,\r\n        desc\r\n      );\r\n\r\n      if (ancestor) {\r\n        for (let sibling = ancestor.nextSibling; sibling; sibling = sibling.nextSibling)\r\n          if (M_get_prompt_parsing_utils.isFunctionDefinition(languageId, sibling)) {\r\n            const comment = M_get_prompt_parsing_utils.getFirstPrecedingComment(sibling);\r\n            const startIdx =\r\n              null !== (r = null == comment ? undefined : comment.startIndex) &&\r\n                undefined !== r\r\n                ? r\r\n                : sibling.startIndex;\r\n            if (startIdx < offset) continue;\r\n            return startIdx;\r\n          }\r\n        if (ancestor.endIndex >= offset)\r\n          return ancestor.endIndex;\r\n      }\r\n    } finally {\r\n      parseTree.delete();\r\n    }\r\n  }\r\n  return offset;\r\n};\r\n"
}